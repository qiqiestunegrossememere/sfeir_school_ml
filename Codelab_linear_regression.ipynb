{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "=============\n",
    "\n",
    "Assignment 1\n",
    "------------\n",
    "\n",
    "The objective of this assignment is to learn how to apply a linear regression algorithm on the iris data set.\n",
    "\n",
    "This notebook uses the [iris](https://archive.ics.uci.edu/ml/datasets/Iris) dataset to be used with python experiments. This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "First we would like to load this data set and visulasation the distribution using the two first two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target_names', 'data', 'target', 'DESCR', 'feature_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAFsCAYAAACEtRP5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHOz/AGUMDlIHrRlMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1070d5250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "print iris.keys()\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 2].min() - .5, X[:, 2].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 2], c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[2])\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we would like to predict the length of petal by using the length of sepal. In this case, the \"sepal length\" is the input value and the \"petal length\" is the target value. In order to apply the Machine Learning algotirthm in the h2o, first we need to import the H2o library and initialization the H2o flow. See the installation document, if the \"h2o\" is not installed in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function init in module h2o.h2o:\n",
      "\n",
      "init(url=None, ip=None, port=None, https=None, insecure=False, username=None, password=None, cluster_name=None, proxy=None, start_h2o=True, nthreads=-1, ice_root=None, enable_assertions=True, max_mem_size=None, min_mem_size=None, strict_version_check=True, **kwargs)\n",
      "    Attempt to connect to a local server, or if not successful start a new server and connect to it.\n",
      "    \n",
      "    :param url:\n",
      "    :param ip:\n",
      "    :param port:\n",
      "    :param https:\n",
      "    :param insecure:\n",
      "    :param username:\n",
      "    :param password:\n",
      "    :param cluster_name:\n",
      "    :param proxy:\n",
      "    :param start_h2o:\n",
      "    :param nthreads:\n",
      "    :param ice_root:\n",
      "    :param enable_assertions:\n",
      "    :param max_mem_size:\n",
      "    :param min_mem_size:\n",
      "    :param strict_version_check:\n",
      "    :param kwargs: (all other deprecated attributes)\n",
      "    :returns: nothing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "#Use help to get the details of the using function\n",
    "help(h2o.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything works, an H2o instance will be lanunch at http://localhost:54321. By taping this adress in your web browser, we can observe that the H2o Web UI is in place. We can directly develop the ML algorithm by using the Web UI. But for this assignment, we use the H2o's API for python.\n",
    "![title](./h2o_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo is provided by H2o, you can also entre \"h2o.demo(\"glm\")\" to run this demo in your console. The demo is for a classification problem, but the principale remains the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Upload the prostate dataset\n",
    "prostate =  h2o.import_file(path=\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/logreg/prostate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>ID           </th><th>CAPSULE       </th><th>AGE          </th><th>RACE          </th><th>DPROS        </th><th>DCAPS         </th><th>PSA          </th><th>VOL          </th><th>GLEASON      </th></tr>\n",
       "<tr><td>type   </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>real         </td><td>real         </td><td>int          </td></tr>\n",
       "<tr><td>mins   </td><td>1.0          </td><td>0.0           </td><td>43.0         </td><td>0.0           </td><td>1.0          </td><td>1.0           </td><td>0.3          </td><td>0.0          </td><td>0.0          </td></tr>\n",
       "<tr><td>mean   </td><td>190.5        </td><td>0.402631578947</td><td>66.0394736842</td><td>1.08684210526 </td><td>2.27105263158</td><td>1.10789473684 </td><td>15.4086315789</td><td>15.8129210526</td><td>6.38421052632</td></tr>\n",
       "<tr><td>maxs   </td><td>380.0        </td><td>1.0           </td><td>79.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>139.7        </td><td>97.6         </td><td>9.0          </td></tr>\n",
       "<tr><td>sigma  </td><td>109.840793879</td><td>0.491074338963</td><td>6.52707126917</td><td>0.308773258025</td><td>1.00010761815</td><td>0.310656449351</td><td>19.9975726686</td><td>18.3476199673</td><td>1.09195337443</td></tr>\n",
       "<tr><td>zeros  </td><td>0            </td><td>227           </td><td>0            </td><td>3             </td><td>0            </td><td>0             </td><td>0            </td><td>167          </td><td>2            </td></tr>\n",
       "<tr><td>missing</td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0            </td><td>0            </td></tr>\n",
       "<tr><td>0      </td><td>1.0          </td><td>0.0           </td><td>65.0         </td><td>1.0           </td><td>2.0          </td><td>1.0           </td><td>1.4          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>1      </td><td>2.0          </td><td>0.0           </td><td>72.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>6.7          </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>2      </td><td>3.0          </td><td>0.0           </td><td>70.0         </td><td>1.0           </td><td>1.0          </td><td>2.0           </td><td>4.9          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>3      </td><td>4.0          </td><td>0.0           </td><td>76.0         </td><td>2.0           </td><td>2.0          </td><td>1.0           </td><td>51.2         </td><td>20.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>4      </td><td>5.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>12.3         </td><td>55.9         </td><td>6.0          </td></tr>\n",
       "<tr><td>5      </td><td>6.0          </td><td>1.0           </td><td>71.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>3.3          </td><td>0.0          </td><td>8.0          </td></tr>\n",
       "<tr><td>6      </td><td>7.0          </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>31.9         </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>7      </td><td>8.0          </td><td>0.0           </td><td>61.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>66.7         </td><td>27.2         </td><td>7.0          </td></tr>\n",
       "<tr><td>8      </td><td>9.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>3.9          </td><td>24.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>9      </td><td>10.0         </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>1.0          </td><td>2.0           </td><td>13.0         </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a description of the prostate data\n",
    "prostate.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split the dataset into ~70/30, training/test sets\n",
    "r = prostate[0].runif()\n",
    "train = prostate[r < 0.70]\n",
    "test = prostate[r >= 0.70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response columns to factors (for binary classification problems)\n",
    "train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n",
    "test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Build a (classification) GLM\n",
    "from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "prostate_glm = H2OGeneralizedLinearEstimator(family=\"binomial\", alpha=[0.5])\n",
    "prostate_glm.train(x=[\"AGE\", \"RACE\", \"PSA\", \"VOL\", \"GLEASON\"],y=\"CAPSULE\", training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1473776316012_5\n",
      "GLM Model: summary\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>family</b></td>\n",
       "<td><b>link</b></td>\n",
       "<td><b>regularization</b></td>\n",
       "<td><b>number_of_predictors_total</b></td>\n",
       "<td><b>number_of_active_predictors</b></td>\n",
       "<td><b>number_of_iterations</b></td>\n",
       "<td><b>training_frame</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>binomial</td>\n",
       "<td>logit</td>\n",
       "<td>Elastic Net (alpha = 0.5, lambda = 4.381E-4 )</td>\n",
       "<td>5</td>\n",
       "<td>5</td>\n",
       "<td>4</td>\n",
       "<td>py_4_sid_9456</td></tr></table></div>"
      ],
      "text/plain": [
       "    family    link    regularization                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
       "--  --------  ------  ---------------------------------------------  ----------------------------  -----------------------------  ----------------------  ----------------\n",
       "    binomial  logit   Elastic Net (alpha = 0.5, lambda = 4.381E-4 )  5                             5                              4                       py_4_sid_9456"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.17960116283\n",
      "RMSE: 0.42379377394\n",
      "LogLoss: 0.530759222893\n",
      "Null degrees of freedom: 266\n",
      "Residual degrees of freedom: 261\n",
      "Null deviance: 360.338902221\n",
      "Residual deviance: 283.425425025\n",
      "AIC: 295.425425025\n",
      "AUC: 0.792860470533\n",
      "Gini: 0.585720941067\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.296910509916: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>106.0</td>\n",
       "<td>53.0</td>\n",
       "<td>0.3333</td>\n",
       "<td> (53.0/159.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>21.0</td>\n",
       "<td>87.0</td>\n",
       "<td>0.1944</td>\n",
       "<td> (21.0/108.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>127.0</td>\n",
       "<td>140.0</td>\n",
       "<td>0.2772</td>\n",
       "<td> (74.0/267.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      106  53   0.3333   (53.0/159.0)\n",
       "1      21   87   0.1944   (21.0/108.0)\n",
       "Total  127  140  0.2772   (74.0/267.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2969105</td>\n",
       "<td>0.7016129</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2244281</td>\n",
       "<td>0.8072100</td>\n",
       "<td>204.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5179445</td>\n",
       "<td>0.6762295</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5179445</td>\n",
       "<td>0.7340824</td>\n",
       "<td>93.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9967267</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1076114</td>\n",
       "<td>1.0</td>\n",
       "<td>243.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9967267</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2969105</td>\n",
       "<td>0.4640780</td>\n",
       "<td>138.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3883907</td>\n",
       "<td>0.7222222</td>\n",
       "<td>117.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2969105</td>\n",
       "<td>0.7361111</td>\n",
       "<td>138.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.296911     0.701613  138\n",
       "max f2                       0.224428     0.80721   204\n",
       "max f0point5                 0.517944     0.67623   93\n",
       "max accuracy                 0.517944     0.734082  93\n",
       "max precision                0.996727     1         0\n",
       "max recall                   0.107611     1         243\n",
       "max specificity              0.996727     1         0\n",
       "max absolute_mcc             0.296911     0.464078  138\n",
       "max min_per_class_accuracy   0.388391     0.722222  117\n",
       "max mean_per_class_accuracy  0.296911     0.736111  138"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 40.45 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0112360</td>\n",
       "<td>0.9645704</td>\n",
       "<td>2.4722222</td>\n",
       "<td>2.4722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0277778</td>\n",
       "<td>147.2222222</td>\n",
       "<td>147.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0224719</td>\n",
       "<td>0.9522347</td>\n",
       "<td>2.4722222</td>\n",
       "<td>2.4722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.0555556</td>\n",
       "<td>147.2222222</td>\n",
       "<td>147.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0299625</td>\n",
       "<td>0.9441000</td>\n",
       "<td>2.4722222</td>\n",
       "<td>2.4722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.0740741</td>\n",
       "<td>147.2222222</td>\n",
       "<td>147.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0411985</td>\n",
       "<td>0.9296140</td>\n",
       "<td>2.4722222</td>\n",
       "<td>2.4722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1018519</td>\n",
       "<td>147.2222222</td>\n",
       "<td>147.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0524345</td>\n",
       "<td>0.9159345</td>\n",
       "<td>2.4722222</td>\n",
       "<td>2.4722222</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.1296296</td>\n",
       "<td>147.2222222</td>\n",
       "<td>147.2222222</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1011236</td>\n",
       "<td>0.7627942</td>\n",
       "<td>1.9017094</td>\n",
       "<td>2.1975309</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.8888889</td>\n",
       "<td>0.0925926</td>\n",
       "<td>0.2222222</td>\n",
       "<td>90.1709402</td>\n",
       "<td>119.7530864</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1498127</td>\n",
       "<td>0.6925134</td>\n",
       "<td>1.5213675</td>\n",
       "<td>1.9777778</td>\n",
       "<td>0.6153846</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.2962963</td>\n",
       "<td>52.1367521</td>\n",
       "<td>97.7777778</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2022472</td>\n",
       "<td>0.6179582</td>\n",
       "<td>1.2361111</td>\n",
       "<td>1.7854938</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7222222</td>\n",
       "<td>0.0648148</td>\n",
       "<td>0.3611111</td>\n",
       "<td>23.6111111</td>\n",
       "<td>78.5493827</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2996255</td>\n",
       "<td>0.5489215</td>\n",
       "<td>1.7115385</td>\n",
       "<td>1.7614583</td>\n",
       "<td>0.6923077</td>\n",
       "<td>0.7125</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.5277778</td>\n",
       "<td>71.1538462</td>\n",
       "<td>76.1458333</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4007491</td>\n",
       "<td>0.4823168</td>\n",
       "<td>1.1903292</td>\n",
       "<td>1.6173416</td>\n",
       "<td>0.4814815</td>\n",
       "<td>0.6542056</td>\n",
       "<td>0.1203704</td>\n",
       "<td>0.6481481</td>\n",
       "<td>19.0329218</td>\n",
       "<td>61.7341641</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5018727</td>\n",
       "<td>0.3054188</td>\n",
       "<td>1.1903292</td>\n",
       "<td>1.5313018</td>\n",
       "<td>0.4814815</td>\n",
       "<td>0.6194030</td>\n",
       "<td>0.1203704</td>\n",
       "<td>0.7685185</td>\n",
       "<td>19.0329218</td>\n",
       "<td>53.1301824</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5992509</td>\n",
       "<td>0.2713034</td>\n",
       "<td>0.6655983</td>\n",
       "<td>1.390625</td>\n",
       "<td>0.2692308</td>\n",
       "<td>0.5625</td>\n",
       "<td>0.0648148</td>\n",
       "<td>0.8333333</td>\n",
       "<td>-33.4401709</td>\n",
       "<td>39.0625</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7003745</td>\n",
       "<td>0.2536711</td>\n",
       "<td>0.8240741</td>\n",
       "<td>1.3088235</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.5294118</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.9166667</td>\n",
       "<td>-17.5925926</td>\n",
       "<td>30.8823529</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7977528</td>\n",
       "<td>0.1508132</td>\n",
       "<td>0.3803419</td>\n",
       "<td>1.1954877</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.4835681</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9537037</td>\n",
       "<td>-61.9658120</td>\n",
       "<td>19.5487741</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8988764</td>\n",
       "<td>0.1106821</td>\n",
       "<td>0.3662551</td>\n",
       "<td>1.1021991</td>\n",
       "<td>0.1481481</td>\n",
       "<td>0.4458333</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9907407</td>\n",
       "<td>-63.3744856</td>\n",
       "<td>10.2199074</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0006563</td>\n",
       "<td>0.0915638</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.4044944</td>\n",
       "<td>0.0092593</td>\n",
       "<td>1.0</td>\n",
       "<td>-90.8436214</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.011236                    0.96457            2.47222    2.47222            1                1                           0.0277778       0.0277778                  147.222   147.222\n",
       "    2        0.0224719                   0.952235           2.47222    2.47222            1                1                           0.0277778       0.0555556                  147.222   147.222\n",
       "    3        0.0299625                   0.9441             2.47222    2.47222            1                1                           0.0185185       0.0740741                  147.222   147.222\n",
       "    4        0.0411985                   0.929614           2.47222    2.47222            1                1                           0.0277778       0.101852                   147.222   147.222\n",
       "    5        0.0524345                   0.915935           2.47222    2.47222            1                1                           0.0277778       0.12963                    147.222   147.222\n",
       "    6        0.101124                    0.762794           1.90171    2.19753            0.769231         0.888889                    0.0925926       0.222222                   90.1709   119.753\n",
       "    7        0.149813                    0.692513           1.52137    1.97778            0.615385         0.8                         0.0740741       0.296296                   52.1368   97.7778\n",
       "    8        0.202247                    0.617958           1.23611    1.78549            0.5              0.722222                    0.0648148       0.361111                   23.6111   78.5494\n",
       "    9        0.299625                    0.548922           1.71154    1.76146            0.692308         0.7125                      0.166667        0.527778                   71.1538   76.1458\n",
       "    10       0.400749                    0.482317           1.19033    1.61734            0.481481         0.654206                    0.12037         0.648148                   19.0329   61.7342\n",
       "    11       0.501873                    0.305419           1.19033    1.5313             0.481481         0.619403                    0.12037         0.768519                   19.0329   53.1302\n",
       "    12       0.599251                    0.271303           0.665598   1.39062            0.269231         0.5625                      0.0648148       0.833333                   -33.4402  39.0625\n",
       "    13       0.700375                    0.253671           0.824074   1.30882            0.333333         0.529412                    0.0833333       0.916667                   -17.5926  30.8824\n",
       "    14       0.797753                    0.150813           0.380342   1.19549            0.153846         0.483568                    0.037037        0.953704                   -61.9658  19.5488\n",
       "    15       0.898876                    0.110682           0.366255   1.1022             0.148148         0.445833                    0.037037        0.990741                   -63.3745  10.2199\n",
       "    16       1                           0.000656323        0.0915638  1                  0.037037         0.404494                    0.00925926      1                          -90.8436  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iteration</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:12:45</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>180.1694511</td>\n",
       "<td>0.6747920</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:12:45</td>\n",
       "<td> 0.122 sec</td>\n",
       "<td>1</td>\n",
       "<td>145.1127643</td>\n",
       "<td>0.5438926</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:12:45</td>\n",
       "<td> 0.148 sec</td>\n",
       "<td>2</td>\n",
       "<td>141.8303323</td>\n",
       "<td>0.5318080</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:12:45</td>\n",
       "<td> 0.199 sec</td>\n",
       "<td>3</td>\n",
       "<td>141.7134799</td>\n",
       "<td>0.5314234</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:12:46</td>\n",
       "<td> 0.256 sec</td>\n",
       "<td>4</td>\n",
       "<td>141.7127125</td>\n",
       "<td>0.5314228</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iteration    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  -----------  -------------------------  -----------\n",
       "    2016-09-14 14:12:45  0.000 sec   0            180.169                    0.674792\n",
       "    2016-09-14 14:12:45  0.122 sec   1            145.113                    0.543893\n",
       "    2016-09-14 14:12:45  0.148 sec   2            141.83                     0.531808\n",
       "    2016-09-14 14:12:45  0.199 sec   3            141.713                    0.531423\n",
       "    2016-09-14 14:12:46  0.256 sec   4            141.713                    0.531423"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the model\n",
    "prostate_glm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">      p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.495215</td><td style=\"text-align: right;\">0.504785 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.730431</td><td style=\"text-align: right;\">0.269569 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.551276</td><td style=\"text-align: right;\">0.448724 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.72343 </td><td style=\"text-align: right;\">0.27657  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.398458</td><td style=\"text-align: right;\">0.601542 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.889811</td><td style=\"text-align: right;\">0.110189 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.960382</td><td style=\"text-align: right;\">0.0396179</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.49595 </td><td style=\"text-align: right;\">0.50405  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.248057</td><td style=\"text-align: right;\">0.751943 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.43444 </td><td style=\"text-align: right;\">0.56556  </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test set and show the first ten predictions\n",
    "predictions = prostate_glm.predict(test)\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.179417281391\n",
      "RMSE: 0.423576771543\n",
      "LogLoss: 0.52709358672\n",
      "Null degrees of freedom: 112\n",
      "Residual degrees of freedom: 107\n",
      "Null deviance: 151.955414855\n",
      "Residual deviance: 119.123150599\n",
      "AIC: 131.123150599\n",
      "AUC: 0.793790849673\n",
      "Gini: 0.587581699346\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.304270781192: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>44.0</td>\n",
       "<td>24.0</td>\n",
       "<td>0.3529</td>\n",
       "<td> (24.0/68.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>9.0</td>\n",
       "<td>36.0</td>\n",
       "<td>0.2</td>\n",
       "<td> (9.0/45.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>53.0</td>\n",
       "<td>60.0</td>\n",
       "<td>0.292</td>\n",
       "<td> (33.0/113.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      44   24   0.3529   (24.0/68.0)\n",
       "1      9    36   0.2      (9.0/45.0)\n",
       "Total  53   60   0.292    (33.0/113.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3042708</td>\n",
       "<td>0.6857143</td>\n",
       "<td>59.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1246993</td>\n",
       "<td>0.8093525</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5655605</td>\n",
       "<td>0.7453416</td>\n",
       "<td>28.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5655605</td>\n",
       "<td>0.7699115</td>\n",
       "<td>28.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9840998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1246993</td>\n",
       "<td>1.0</td>\n",
       "<td>97.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9840998</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.5655605</td>\n",
       "<td>0.5153411</td>\n",
       "<td>28.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4668071</td>\n",
       "<td>0.6888889</td>\n",
       "<td>51.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.5655605</td>\n",
       "<td>0.7299020</td>\n",
       "<td>28.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.304271     0.685714  59\n",
       "max f2                       0.124699     0.809353  97\n",
       "max f0point5                 0.56556      0.745342  28\n",
       "max accuracy                 0.56556      0.769912  28\n",
       "max precision                0.9841       1         0\n",
       "max recall                   0.124699     1         97\n",
       "max specificity              0.9841       1         0\n",
       "max absolute_mcc             0.56556      0.515341  28\n",
       "max min_per_class_accuracy   0.466807     0.688889  51\n",
       "max mean_per_class_accuracy  0.56556      0.729902  28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 39.82 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0176991</td>\n",
       "<td>0.9712175</td>\n",
       "<td>2.5111111</td>\n",
       "<td>2.5111111</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0444444</td>\n",
       "<td>0.0444444</td>\n",
       "<td>151.1111111</td>\n",
       "<td>151.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0265487</td>\n",
       "<td>0.9543722</td>\n",
       "<td>2.5111111</td>\n",
       "<td>2.5111111</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0222222</td>\n",
       "<td>0.0666667</td>\n",
       "<td>151.1111111</td>\n",
       "<td>151.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0353982</td>\n",
       "<td>0.9289485</td>\n",
       "<td>2.5111111</td>\n",
       "<td>2.5111111</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0222222</td>\n",
       "<td>0.0888889</td>\n",
       "<td>151.1111111</td>\n",
       "<td>151.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0442478</td>\n",
       "<td>0.9235636</td>\n",
       "<td>2.5111111</td>\n",
       "<td>2.5111111</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0222222</td>\n",
       "<td>0.1111111</td>\n",
       "<td>151.1111111</td>\n",
       "<td>151.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0530973</td>\n",
       "<td>0.9193106</td>\n",
       "<td>2.5111111</td>\n",
       "<td>2.5111111</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0222222</td>\n",
       "<td>0.1333333</td>\n",
       "<td>151.1111111</td>\n",
       "<td>151.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1061947</td>\n",
       "<td>0.8169395</td>\n",
       "<td>2.5111111</td>\n",
       "<td>2.5111111</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.2666667</td>\n",
       "<td>151.1111111</td>\n",
       "<td>151.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1504425</td>\n",
       "<td>0.6544068</td>\n",
       "<td>1.0044444</td>\n",
       "<td>2.0679739</td>\n",
       "<td>0.4</td>\n",
       "<td>0.8235294</td>\n",
       "<td>0.0444444</td>\n",
       "<td>0.3111111</td>\n",
       "<td>0.4444444</td>\n",
       "<td>106.7973856</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2035398</td>\n",
       "<td>0.5992996</td>\n",
       "<td>2.0925926</td>\n",
       "<td>2.0743961</td>\n",
       "<td>0.8333333</td>\n",
       "<td>0.8260870</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.4222222</td>\n",
       "<td>109.2592593</td>\n",
       "<td>107.4396135</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3008850</td>\n",
       "<td>0.5217981</td>\n",
       "<td>1.3696970</td>\n",
       "<td>1.8464052</td>\n",
       "<td>0.5454545</td>\n",
       "<td>0.7352941</td>\n",
       "<td>0.1333333</td>\n",
       "<td>0.5555556</td>\n",
       "<td>36.9696970</td>\n",
       "<td>84.6405229</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3982301</td>\n",
       "<td>0.5039021</td>\n",
       "<td>0.9131313</td>\n",
       "<td>1.6182716</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.6444444</td>\n",
       "<td>0.0888889</td>\n",
       "<td>0.6444444</td>\n",
       "<td>-8.6868687</td>\n",
       "<td>61.8271605</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5044248</td>\n",
       "<td>0.3376480</td>\n",
       "<td>0.8370370</td>\n",
       "<td>1.4538012</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.5789474</td>\n",
       "<td>0.0888889</td>\n",
       "<td>0.7333333</td>\n",
       "<td>-16.2962963</td>\n",
       "<td>45.3801170</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6017699</td>\n",
       "<td>0.2917215</td>\n",
       "<td>0.9131313</td>\n",
       "<td>1.3663399</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.5441176</td>\n",
       "<td>0.0888889</td>\n",
       "<td>0.8222222</td>\n",
       "<td>-8.6868687</td>\n",
       "<td>36.6339869</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6991150</td>\n",
       "<td>0.2699825</td>\n",
       "<td>0.4565657</td>\n",
       "<td>1.2396624</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.4936709</td>\n",
       "<td>0.0444444</td>\n",
       "<td>0.8666667</td>\n",
       "<td>-54.3434343</td>\n",
       "<td>23.9662447</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7964602</td>\n",
       "<td>0.2305066</td>\n",
       "<td>0.9131313</td>\n",
       "<td>1.1997531</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.4777778</td>\n",
       "<td>0.0888889</td>\n",
       "<td>0.9555556</td>\n",
       "<td>-8.6868687</td>\n",
       "<td>19.9753086</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8938053</td>\n",
       "<td>0.1159187</td>\n",
       "<td>0.4565657</td>\n",
       "<td>1.1188119</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.4455446</td>\n",
       "<td>0.0444444</td>\n",
       "<td>1.0</td>\n",
       "<td>-54.3434343</td>\n",
       "<td>11.8811881</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0396179</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3982301</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0176991                   0.971217           2.51111   2.51111            1                1                           0.0444444       0.0444444                  151.111   151.111\n",
       "    2        0.0265487                   0.954372           2.51111   2.51111            1                1                           0.0222222       0.0666667                  151.111   151.111\n",
       "    3        0.0353982                   0.928948           2.51111   2.51111            1                1                           0.0222222       0.0888889                  151.111   151.111\n",
       "    4        0.0442478                   0.923564           2.51111   2.51111            1                1                           0.0222222       0.111111                   151.111   151.111\n",
       "    5        0.0530973                   0.919311           2.51111   2.51111            1                1                           0.0222222       0.133333                   151.111   151.111\n",
       "    6        0.106195                    0.816939           2.51111   2.51111            1                1                           0.133333        0.266667                   151.111   151.111\n",
       "    7        0.150442                    0.654407           1.00444   2.06797            0.4              0.823529                    0.0444444       0.311111                   0.444444  106.797\n",
       "    8        0.20354                     0.5993             2.09259   2.0744             0.833333         0.826087                    0.111111        0.422222                   109.259   107.44\n",
       "    9        0.300885                    0.521798           1.3697    1.84641            0.545455         0.735294                    0.133333        0.555556                   36.9697   84.6405\n",
       "    10       0.39823                     0.503902           0.913131  1.61827            0.363636         0.644444                    0.0888889       0.644444                   -8.68687  61.8272\n",
       "    11       0.504425                    0.337648           0.837037  1.4538             0.333333         0.578947                    0.0888889       0.733333                   -16.2963  45.3801\n",
       "    12       0.60177                     0.291721           0.913131  1.36634            0.363636         0.544118                    0.0888889       0.822222                   -8.68687  36.634\n",
       "    13       0.699115                    0.269983           0.456566  1.23966            0.181818         0.493671                    0.0444444       0.866667                   -54.3434  23.9662\n",
       "    14       0.79646                     0.230507           0.913131  1.19975            0.363636         0.477778                    0.0888889       0.955556                   -8.68687  19.9753\n",
       "    15       0.893805                    0.115919           0.456566  1.11881            0.181818         0.445545                    0.0444444       1                          -54.3434  11.8812\n",
       "    16       1                           0.0396179          0         1                  0                0.39823                     0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Show default performance metrics\n",
    "performance = prostate_glm.model_performance(test)\n",
    "performance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "------------\n",
    "Please convert your demo for the iris data set. We note that our problem is a regression problem. \n",
    "Using help() to give a more details of the H2OGeneralizedLinearEstimator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class H2OGeneralizedLinearEstimator in module h2o.estimators.glm:\n",
      "\n",
      "class H2OGeneralizedLinearEstimator(h2o.estimators.estimator_base.H2OEstimator)\n",
      " |  Generalized Linear Modeling\n",
      " |  \n",
      " |  Fits a generalized linear model, specified by a response variable, a set of predictors, and a\n",
      " |  description of the error distribution.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |    model_id : str\n",
      " |      Destination id for this model; auto-generated if not specified.\n",
      " |  \n",
      " |    training_frame : str\n",
      " |      Id of the training data frame (Not required, to allow initial validation of model parameters).\n",
      " |  \n",
      " |    validation_frame : str\n",
      " |      Id of the validation data frame.\n",
      " |  \n",
      " |    nfolds : int\n",
      " |      Number of folds for N-fold cross-validation (0 to disable or >= 2).\n",
      " |      Default: 0\n",
      " |  \n",
      " |    seed : int\n",
      " |      Seed for pseudo random number generator (if applicable)\n",
      " |      Default: -1\n",
      " |  \n",
      " |    keep_cross_validation_predictions : bool\n",
      " |      Whether to keep the predictions of the cross-validation models.\n",
      " |      Default: False\n",
      " |  \n",
      " |    keep_cross_validation_fold_assignment : bool\n",
      " |      Whether to keep the cross-validation fold assignment.\n",
      " |      Default: False\n",
      " |  \n",
      " |    fold_assignment : \"AUTO\" | \"Random\" | \"Modulo\" | \"Stratified\"\n",
      " |      Cross-validation fold assignment scheme, if fold_column is not specified. The 'Stratified' option will stratify\n",
      " |      the folds based on the response variable, for classification problems.\n",
      " |      Default: \"AUTO\"\n",
      " |  \n",
      " |    fold_column : VecSpecifier\n",
      " |      Column with cross-validation fold index assignment per observation.\n",
      " |  \n",
      " |    response_column : VecSpecifier\n",
      " |      Response variable column.\n",
      " |  \n",
      " |    ignored_columns : list(str)\n",
      " |      Names of columns to ignore for training.\n",
      " |  \n",
      " |    ignore_const_cols : bool\n",
      " |      Ignore constant columns.\n",
      " |      Default: True\n",
      " |  \n",
      " |    score_each_iteration : bool\n",
      " |      Whether to score during each iteration of model training.\n",
      " |      Default: False\n",
      " |  \n",
      " |    offset_column : VecSpecifier\n",
      " |      Offset column. This will be added to the combination of columns before applying the link function.\n",
      " |  \n",
      " |    weights_column : VecSpecifier\n",
      " |      Column with observation weights. Giving some observation a weight of zero is equivalent to excluding it from the\n",
      " |      dataset; giving an observation a relative weight of 2 is equivalent to repeating that row twice. Negative\n",
      " |      weights are not allowed.\n",
      " |  \n",
      " |    family : \"gaussian\" | \"binomial\" | \"multinomial\" | \"poisson\" | \"gamma\" | \"tweedie\"\n",
      " |      Family. Use binomial for classification with logistic regression, others are for regression problems.\n",
      " |      Default: \"gaussian\"\n",
      " |  \n",
      " |    tweedie_variance_power : float\n",
      " |      Tweedie variance power\n",
      " |      Default: 0.0\n",
      " |  \n",
      " |    tweedie_link_power : float\n",
      " |      Tweedie link power\n",
      " |      Default: 1.0\n",
      " |  \n",
      " |    solver : \"AUTO\" | \"IRLSM\" | \"L_BFGS\" | \"COORDINATE_DESCENT_NAIVE\" | \"COORDINATE_DESCENT\"\n",
      " |      AUTO will set the solver based on given data and the other parameters. IRLSM is fast on on problems with small\n",
      " |      number of predictors and for lambda-search with L1 penalty, L_BFGS scales better for datasets with many columns.\n",
      " |      Coordinate descent is experimental (beta).\n",
      " |      Default: \"AUTO\"\n",
      " |  \n",
      " |    alpha : list(float)\n",
      " |      distribution of regularization between L1 and L2.\n",
      " |  \n",
      " |    lambda_ : list(float)\n",
      " |      regularization strength\n",
      " |  \n",
      " |    lambda_search : bool\n",
      " |      use lambda search starting at lambda max, given lambda is then interpreted as lambda min\n",
      " |      Default: False\n",
      " |  \n",
      " |    early_stopping : bool\n",
      " |      stop early when there is no more relative improvement on train or validation (if provided)\n",
      " |      Default: True\n",
      " |  \n",
      " |    nlambdas : int\n",
      " |      number of lambdas to be used in a search\n",
      " |      Default: -1\n",
      " |  \n",
      " |    standardize : bool\n",
      " |      Standardize numeric columns to have zero mean and unit variance\n",
      " |      Default: True\n",
      " |  \n",
      " |    missing_values_handling : \"Skip\" | \"MeanImputation\"\n",
      " |      Handling of missing values. Either Skip or MeanImputation.\n",
      " |      Default: \"MeanImputation\"\n",
      " |  \n",
      " |    compute_p_values : bool\n",
      " |      request p-values computation, p-values work only with IRLSM solver and no regularization\n",
      " |      Default: False\n",
      " |  \n",
      " |    remove_collinear_columns : bool\n",
      " |      in case of linearly dependent columns remove some of the dependent columns\n",
      " |      Default: False\n",
      " |  \n",
      " |    intercept : bool\n",
      " |      include constant term in the model\n",
      " |      Default: True\n",
      " |  \n",
      " |    non_negative : bool\n",
      " |      Restrict coefficients (not intercept) to be non-negative\n",
      " |      Default: False\n",
      " |  \n",
      " |    max_iterations : int\n",
      " |      Maximum number of iterations\n",
      " |      Default: -1\n",
      " |  \n",
      " |    objective_epsilon : float\n",
      " |      converge if  objective value changes less than this\n",
      " |      Default: -1.0\n",
      " |  \n",
      " |    beta_epsilon : float\n",
      " |      converge if  beta changes less (using L-infinity norm) than beta esilon, ONLY applies to IRLSM solver\n",
      " |      Default: 0.0001\n",
      " |  \n",
      " |    gradient_epsilon : float\n",
      " |      converge if  objective changes less (using L-infinity norm) than this, ONLY applies to L-BFGS solver\n",
      " |      Default: -1.0\n",
      " |  \n",
      " |    link : \"family_default\" | \"identity\" | \"logit\" | \"log\" | \"inverse\" | \"tweedie\"\n",
      " |  \n",
      " |      Default: \"family_default\"\n",
      " |  \n",
      " |    prior : float\n",
      " |      prior probability for y==1. To be used only for logistic regression iff the data has been sampled and the mean\n",
      " |      of response does not reflect reality.\n",
      " |      Default: -1.0\n",
      " |  \n",
      " |    lambda_min_ratio : float\n",
      " |      min lambda used in lambda search, specified as a ratio of lambda_max\n",
      " |      Default: -1.0\n",
      " |  \n",
      " |    beta_constraints : str\n",
      " |      beta constraints\n",
      " |  \n",
      " |    max_active_predictors : int\n",
      " |      Maximum number of active predictors during computation. Use as a stopping criterium to prevent expensive model\n",
      " |      building with many predictors.\n",
      " |      Default: -1\n",
      " |  \n",
      " |    interactions : list(str)\n",
      " |      A list of predictor column indices to interact. All pairwise combinations will be computed for the list.\n",
      " |  \n",
      " |    balance_classes : bool\n",
      " |      Balance training data class counts via over/under-sampling (for imbalanced data).\n",
      " |      Default: False\n",
      " |  \n",
      " |    class_sampling_factors : list(float)\n",
      " |      Desired over/under-sampling ratios per class (in lexicographic order). If not specified, sampling factors will\n",
      " |      be automatically computed to obtain class balance during training. Requires balance_classes.\n",
      " |  \n",
      " |    max_after_balance_size : float\n",
      " |      Maximum relative size of the training data after balancing class counts (can be less than 1.0). Requires\n",
      " |      balance_classes.\n",
      " |      Default: 5.0\n",
      " |  \n",
      " |    max_confusion_matrix_size : int\n",
      " |      Maximum size (# classes) for confusion matrices to be printed in the Logs\n",
      " |      Default: 20\n",
      " |  \n",
      " |    max_hit_ratio_k : int\n",
      " |      Max. number (top K) of predictions to use for hit ratio computation (for multi-class only, 0 to disable)\n",
      " |      Default: 0\n",
      " |  \n",
      " |    max_runtime_secs : float\n",
      " |      Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |      Default: 0.0\n",
      " |  \n",
      " |  Returns\n",
      " |  -------\n",
      " |  A subclass of ModelBase is returned. The specific subclass depends on the machine learning task at hand\n",
      " |  (if it's binomial classification, then an H2OBinomialModel is returned, if it's regression then a\n",
      " |  H2ORegressionModel is returned). The default print-out of the models is shown, but further GLM-specific\n",
      " |  information can be queried out of the object. Upon completion of the GLM, the resulting object has\n",
      " |  coefficients, normalized coefficients, residual/null deviance, aic, and a host of model metrics including\n",
      " |  MSE, AUC (for logistic regression), degrees of freedom, and confusion matrices.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      H2OGeneralizedLinearEstimator\n",
      " |      h2o.estimators.estimator_base.H2OEstimator\n",
      " |      h2o.model.model_base.ModelBase\n",
      " |      h2o.utils.backward_compatibility.BackwardsCompatibleBase\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  getGLMRegularizationPath(model)\n",
      " |      Extract full regularization path explored during lambda search from glm model.\n",
      " |      @param model - source lambda search model\n",
      " |  \n",
      " |  makeGLMModel(model, coefs, threshold=0.5)\n",
      " |      Create a custom GLM model using the given coefficients.\n",
      " |      Needs to be passed source model trained on the dataset to extract the dataset information from.\n",
      " |        @param model - source model, used for extracting dataset information\n",
      " |        @param coefs - dictionary containing model coefficients\n",
      " |        @param threshold - (optional, only for binomial) decision threshold used for classification\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  Lambda\n",
      " |      [DEPRECATED] Use self.lambda_ instead\n",
      " |  \n",
      " |  alpha\n",
      " |  \n",
      " |  balance_classes\n",
      " |  \n",
      " |  beta_constraints\n",
      " |  \n",
      " |  beta_epsilon\n",
      " |  \n",
      " |  class_sampling_factors\n",
      " |  \n",
      " |  compute_p_values\n",
      " |  \n",
      " |  early_stopping\n",
      " |  \n",
      " |  family\n",
      " |  \n",
      " |  fold_assignment\n",
      " |  \n",
      " |  fold_column\n",
      " |  \n",
      " |  gradient_epsilon\n",
      " |  \n",
      " |  ignore_const_cols\n",
      " |  \n",
      " |  ignored_columns\n",
      " |  \n",
      " |  interactions\n",
      " |  \n",
      " |  intercept\n",
      " |  \n",
      " |  keep_cross_validation_fold_assignment\n",
      " |  \n",
      " |  keep_cross_validation_predictions\n",
      " |  \n",
      " |  lambda_\n",
      " |      [DEPRECATED] Use self.lambda_ instead\n",
      " |  \n",
      " |  lambda_min_ratio\n",
      " |  \n",
      " |  lambda_search\n",
      " |  \n",
      " |  link\n",
      " |  \n",
      " |  max_active_predictors\n",
      " |  \n",
      " |  max_after_balance_size\n",
      " |  \n",
      " |  max_confusion_matrix_size\n",
      " |  \n",
      " |  max_hit_ratio_k\n",
      " |  \n",
      " |  max_iterations\n",
      " |  \n",
      " |  max_runtime_secs\n",
      " |  \n",
      " |  missing_values_handling\n",
      " |  \n",
      " |  nfolds\n",
      " |  \n",
      " |  nlambdas\n",
      " |  \n",
      " |  non_negative\n",
      " |  \n",
      " |  objective_epsilon\n",
      " |  \n",
      " |  offset_column\n",
      " |  \n",
      " |  prior\n",
      " |  \n",
      " |  remove_collinear_columns\n",
      " |  \n",
      " |  response_column\n",
      " |  \n",
      " |  score_each_iteration\n",
      " |  \n",
      " |  seed\n",
      " |  \n",
      " |  solver\n",
      " |  \n",
      " |  standardize\n",
      " |  \n",
      " |  training_frame\n",
      " |  \n",
      " |  tweedie_link_power\n",
      " |  \n",
      " |  tweedie_variance_power\n",
      " |  \n",
      " |  validation_frame\n",
      " |  \n",
      " |  weights_column\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  build_model(self, algo_params)\n",
      " |      Helper for model.train().\n",
      " |  \n",
      " |  fit(self, x, y=None, **params)\n",
      " |      Fit an H2O model as part of a scikit-learn pipeline or grid search.\n",
      " |      \n",
      " |      A warning will be issued if a caller other than sklearn attempts to use this method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |          x : H2OFrame\n",
      " |              An H2OFrame consisting of the predictor variables.\n",
      " |      \n",
      " |          y : H2OFrame, optional\n",
      " |              An H2OFrame consisting of the response variable.\n",
      " |      \n",
      " |          params : optional\n",
      " |              Extra arguments.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |          The current instance of H2OEstimator for method chaining.\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Obtain parameters for this estimator.\n",
      " |      \n",
      " |      Used primarily for sklearn Pipelines and sklearn grid search.\n",
      " |      \n",
      " |      :param deep: If True, return parameters of all sub-objects that are estimators.\n",
      " |      \n",
      " |      :returns: A dict of parameters\n",
      " |  \n",
      " |  join(self)\n",
      " |      Wait until job's completion.\n",
      " |  \n",
      " |  set_params(self, **parms)\n",
      " |      Used by sklearn for updating parameters during grid search.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |          parms : dict\n",
      " |              A dictionary of parameters that will be set on this model.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |          Returns self, the current estimator object with the parameters all set as desired.\n",
      " |  \n",
      " |  start(self, x, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, **params)\n",
      " |      Train the model asynchronously.\n",
      " |      \n",
      " |      To block for results, call join.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : list\n",
      " |          A list of column names or indices indicating the predictor columns.\n",
      " |      \n",
      " |      y : str\n",
      " |          An index or a column name indicating the response column.\n",
      " |      \n",
      " |      training_frame : H2OFrame\n",
      " |          The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      \n",
      " |      offset_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the offsets.\n",
      " |      \n",
      " |      fold_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      \n",
      " |      weights_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      \n",
      " |      validation_frame : H2OFrame, optional\n",
      " |          H2OFrame with validation data to be scored on while training.\n",
      " |  \n",
      " |  train(self, x=None, y=None, training_frame=None, offset_column=None, fold_column=None, weights_column=None, validation_frame=None, max_runtime_secs=None, **params)\n",
      " |      Train the H2O model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : list, None\n",
      " |          A list of column names or indices indicating the predictor columns.\n",
      " |      \n",
      " |      y : str, int\n",
      " |          An index or a column name indicating the response column.\n",
      " |      \n",
      " |      training_frame : H2OFrame\n",
      " |          The H2OFrame having the columns indicated by x and y (as well as any\n",
      " |          additional columns specified by fold, offset, and weights).\n",
      " |      \n",
      " |      offset_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the offsets.\n",
      " |      \n",
      " |      fold_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row fold\n",
      " |          assignments.\n",
      " |      \n",
      " |      weights_column : str, optional\n",
      " |          The name or index of the column in training_frame that holds the per-row weights.\n",
      " |      \n",
      " |      validation_frame : H2OFrame, optional\n",
      " |          H2OFrame with validation data to be scored on while training.\n",
      " |      \n",
      " |      max_runtime_secs : float\n",
      " |          Maximum allowed runtime in seconds for model training. Use 0 to disable.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from h2o.estimators.estimator_base.H2OEstimator:\n",
      " |  \n",
      " |  mixin(obj, cls)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  aic(self, train=False, valid=False, xval=False)\n",
      " |      Get the AIC(s).\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the AIC value for the training data.\n",
      " |      :param valid: If valid is True, then return the AIC value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the AIC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AIC.\n",
      " |  \n",
      " |  auc(self, train=False, valid=False, xval=False)\n",
      " |      Get the AUC.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param train: If train is True, then return the AUC value for the training data.\n",
      " |      :param valid: If valid is True, then return the AUC value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the AUC value for the validation data.\n",
      " |      \n",
      " |      :returns: The AUC.\n",
      " |  \n",
      " |  biases(self, vector_id=0)\n",
      " |      Return the frame for the respective bias vector.\n",
      " |      \n",
      " |      :param: vector_id: an integer, ranging from 0 to number of layers, that specifies the bias vector to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the bias vector identified by vector_id\n",
      " |  \n",
      " |  catoffsets(self)\n",
      " |      Categorical offsets for one-hot encoding.\n",
      " |  \n",
      " |  coef(self)\n",
      " |      Return the coefficients for this model.\n",
      " |  \n",
      " |  coef_norm(self)\n",
      " |      Return the normalized coefficients.\n",
      " |  \n",
      " |  cross_validation_fold_assignment(self)\n",
      " |      Obtain the cross-validation fold assignment for all rows in the training data.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_holdout_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on the training data.\n",
      " |      \n",
      " |      This is equivalent to summing up all H2OFrames returned by cross_validation_predictions.\n",
      " |      \n",
      " |      :returns: H2OFrame\n",
      " |  \n",
      " |  cross_validation_metrics_summary(self)\n",
      " |      Retrieve Cross-Validation Metrics Summary.\n",
      " |      \n",
      " |      :returns: The cross-validation metrics summary as an H2OTwoDimTable\n",
      " |  \n",
      " |  cross_validation_models(self)\n",
      " |      Obtain a list of cross-validation models.\n",
      " |      \n",
      " |      :returns: list of H2OModel objects\n",
      " |  \n",
      " |  cross_validation_predictions(self)\n",
      " |      Obtain the (out-of-sample) holdout predictions of all cross-validation models on their holdout data.\n",
      " |      \n",
      " |      Note that the predictions are expanded to the full number of rows of the training data, with 0 fill-in.\n",
      " |      \n",
      " |      :returns: list of H2OFrame objects\n",
      " |  \n",
      " |  deepfeatures(self, test_data, layer)\n",
      " |      Return hidden layer details.\n",
      " |      \n",
      " |      :param test_data: Data to create a feature space on\n",
      " |      :param layer: 0 index hidden layer\n",
      " |  \n",
      " |  download_pojo(self, path=u'')\n",
      " |      Download the POJO for this model to the directory specified by path.\n",
      " |      \n",
      " |      If path is \"\", then dump to screen.\n",
      " |      \n",
      " |      :param path:  An absolute path to the directory where POJO should be saved.\n",
      " |      \n",
      " |      :returns: None\n",
      " |  \n",
      " |  get_xval_models(self, key=None)\n",
      " |      Return a Model object.\n",
      " |      \n",
      " |      :param key: If None, return all cross-validated models; otherwise return the model that key points to.\n",
      " |      \n",
      " |      :returns: A model or list of models.\n",
      " |  \n",
      " |  gini(self, train=False, valid=False, xval=False)\n",
      " |      Get the Gini coefficient.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\"\n",
      " |      \n",
      " |      :param train: If train is True, then return the Gini Coefficient value for the training data.\n",
      " |      :param valid: If valid is True, then return the Gini Coefficient value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Gini Coefficient value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Gini Coefficient for this binomial model.\n",
      " |  \n",
      " |  is_cross_validated(self)\n",
      " |      Return True if the model was cross-validated.\n",
      " |  \n",
      " |  logloss(self, train=False, valid=False, xval=False)\n",
      " |      Get the Log Loss.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param train: If train is True, then return the Log Loss value for the training data.\n",
      " |      :param valid: If valid is True, then return the Log Loss value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Log Loss value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Log Loss for this binomial model.\n",
      " |  \n",
      " |  mae(self, train=False, valid=False, xval=False)\n",
      " |      Get the MAE.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      train : bool, default=True\n",
      " |        If train is True, then return the MAE value for the training data.\n",
      " |      valid : bool, default=True\n",
      " |        If valid is True, then return the MAE value for the validation data.\n",
      " |      xval : bool, default=True\n",
      " |        If xval is True, then return the MAE value for the cross validation data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        The MAE for this regression model.\n",
      " |  \n",
      " |  mean_residual_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Get the Mean Residual Deviances.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param train: If train is True, then return the Mean Residual Deviance value for the training data.\n",
      " |      :param valid: If valid is True, then return the Mean Residual Deviance value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the Mean Residual Deviance value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The Mean Residual Deviance for this regression model.\n",
      " |  \n",
      " |  model_performance(self, test_data=None, train=False, valid=False, xval=False)\n",
      " |      Generate model metrics for this model on test_data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      test_data: H2OFrame, optional\n",
      " |        Data set for which model metrics shall be computed against. All three of train, valid and xval arguments are\n",
      " |        ignored if test_data is not None.\n",
      " |      train: boolean, optional\n",
      " |        Report the training metrics for the model.\n",
      " |      valid: boolean, optional\n",
      " |        Report the validation metrics for the model.\n",
      " |      xval: boolean, optional\n",
      " |        Report the cross-validation metrics for the model. If train and valid are True, then it defaults to True.\n",
      " |      \n",
      " |      :returns: An object of class H2OModelMetrics.\n",
      " |  \n",
      " |  mse(self, train=False, valid=False, xval=False)\n",
      " |      Get the MSE.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      train : bool, default=True\n",
      " |        If train is True, then return the MSE value for the training data.\n",
      " |      valid : bool, default=True\n",
      " |        If valid is True, then return the MSE value for the validation data.\n",
      " |      xval : bool, default=True\n",
      " |        If xval is True, then return the MSE value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The MSE for this regression model.\n",
      " |  \n",
      " |  normmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric predictors.\n",
      " |  \n",
      " |  normsub(self)\n",
      " |      Normalization/Standardization offsets for numeric predictors.\n",
      " |  \n",
      " |  null_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the null dof for the training set. If both train and valid are False, then train is\n",
      " |          selected by default.\n",
      " |      :param valid: Get the null dof for the validation set. If both train and valid are True, then train is\n",
      " |          selected by default.\n",
      " |      :param xval: not implemented\n",
      " |      \n",
      " |      :returns: Return the null dof, or None if it is not present.\n",
      " |  \n",
      " |  null_deviance(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the null deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the null deviance for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param valid: Get the null deviance for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      :param xval: not implemented\n",
      " |      \n",
      " |      :returns: Return the null deviance, or None if it is not present.\n",
      " |  \n",
      " |  pprint_coef(self)\n",
      " |      Pretty print the coefficents table (includes normalized coefficients).\n",
      " |  \n",
      " |  predict(self, test_data)\n",
      " |      Predict on a dataset.\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  predict_leaf_node_assignment(self, test_data)\n",
      " |      Predict on a dataset and return the leaf node assignment (only for tree-based models).\n",
      " |      \n",
      " |      :param H2OFrame test_data: Data on which to make predictions.\n",
      " |      \n",
      " |      :returns: A new H2OFrame of predictions.\n",
      " |  \n",
      " |  r2(self, train=False, valid=False, xval=False)\n",
      " |      Return the R^2 for this regression model.\n",
      " |      \n",
      " |      Will return R^2 for GLM Models and will return NaN otherwise.\n",
      " |      \n",
      " |      The R^2 value is defined to be 1 - MSE/var, where var is computed as sigma*sigma.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      :param train: If train is True, then return the R^2 value for the training data.\n",
      " |      :param valid: If valid is True, then return the R^2 value for the validation data.\n",
      " |      :param xval:  If xval is True, then return the R^2 value for the cross validation data.\n",
      " |      \n",
      " |      :returns: The R^2 for this regression model.\n",
      " |  \n",
      " |  residual_degrees_of_freedom(self, train=False, valid=False, xval=False)\n",
      " |      Retreive the residual degress of freedom if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the residual dof for the training set. If both train and valid are False, then train\n",
      " |          is selected by default.\n",
      " |      :param valid: Get the residual dof for the validation set. If both train and valid are True, then train\n",
      " |          is selected by default.\n",
      " |      :param xval: not implemented\n",
      " |      \n",
      " |      :returns: Return the residual dof, or None if it is not present.\n",
      " |  \n",
      " |  residual_deviance(self, train=False, valid=False, xval=None)\n",
      " |      Retreive the residual deviance if this model has the attribute, or None otherwise.\n",
      " |      \n",
      " |      :param train: Get the residual deviance for the training set. If both train and valid are False, then\n",
      " |          train is selected by default.\n",
      " |      :param valid: Get the residual deviance for the validation set. If both train and valid are True, then\n",
      " |          train is selected by default.\n",
      " |      :param xval: not implemented\n",
      " |      \n",
      " |      :returns: Return the residual deviance, or None if it is not present.\n",
      " |  \n",
      " |  respmul(self)\n",
      " |      Normalization/Standardization multipliers for numeric response.\n",
      " |  \n",
      " |  respsub(self)\n",
      " |      Normalization/Standardization offsets for numeric response.\n",
      " |  \n",
      " |  rmse(self, train=False, valid=False, xval=False)\n",
      " |      Get the RMSE.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      train : bool, default=True\n",
      " |        If train is True, then return the RMSE value for the training data.\n",
      " |      valid : bool, default=True\n",
      " |        If valid is True, then return the RMSE value for the validation data.\n",
      " |      xval : bool, default=True\n",
      " |        If xval is True, then return the RMSE value for the cross validation data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        The RMSE for this regression model.\n",
      " |  \n",
      " |  rmsle(self, train=False, valid=False, xval=False)\n",
      " |      Get the rmsle.\n",
      " |      \n",
      " |      If all are False (default), then return the training metric value.\n",
      " |      If more than one options is set to True, then return a dictionary of metrics where the keys are \"train\",\n",
      " |      \"valid\", and \"xval\".\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      train : bool, default=True\n",
      " |        If train is True, then return the rmsle value for the training data.\n",
      " |      valid : bool, default=True\n",
      " |        If valid is True, then return the rmsle value for the validation data.\n",
      " |      xval : bool, default=True\n",
      " |        If xval is True, then return the rmsle value for the cross validation data.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |        The rmsle for this regression model.\n",
      " |  \n",
      " |  score_history(self)\n",
      " |      [DEPRECATED].\n",
      " |  \n",
      " |  scoring_history(self)\n",
      " |      Retrieve Model Score History.\n",
      " |      \n",
      " |      :returns: The score history as an H2OTwoDimTable or a Pandas DataFrame.\n",
      " |  \n",
      " |  show(self)\n",
      " |      Print innards of model, without regards to type.\n",
      " |  \n",
      " |  std_coef_plot(self, num_of_features=None, server=False)\n",
      " |      Plot a GLM model's standardized coefficient magnitudes.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  summary(self)\n",
      " |      Print a detailed summary of the model.\n",
      " |  \n",
      " |  varimp(self, use_pandas=False)\n",
      " |      Pretty print the variable importances, or return them in a list.\n",
      " |      \n",
      " |      :param use_pandas: If True, then the variable importances will be returned as a pandas data frame.\n",
      " |      \n",
      " |      :returns: A list or Pandas DataFrame.\n",
      " |  \n",
      " |  varimp_plot(self, num_of_features=None, server=False)\n",
      " |      Plot the variable importance for a trained model.\n",
      " |      \n",
      " |      :param num_of_features: the number of features shown in the plot.\n",
      " |      :param server: ?\n",
      " |      \n",
      " |      :returns: None.\n",
      " |  \n",
      " |  weights(self, matrix_id=0)\n",
      " |      Return the frame for the respective weight matrix.\n",
      " |      \n",
      " |      :param: matrix_id: an integer, ranging from 0 to number of layers, that specifies the weight matrix to return.\n",
      " |      \n",
      " |      :returns: an H2OFrame which represents the weight matrix identified by matrix_id\n",
      " |  \n",
      " |  xval_keys(self)\n",
      " |      Return model keys for the cross-validated model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.model.model_base.ModelBase:\n",
      " |  \n",
      " |  actual_params\n",
      " |      Get actual parameters of a model\n",
      " |      \n",
      " |      :return: A dictionary of actual parameters for the model\n",
      " |  \n",
      " |  default_params\n",
      " |      Get default parameters of a model\n",
      " |      \n",
      " |      :return: A dictionary of default parameters for the model\n",
      " |  \n",
      " |  full_parameters\n",
      " |      Get the full specification of all parameters.\n",
      " |      \n",
      " |      :returns: a dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  model_id\n",
      " |      Model identifier.\n",
      " |  \n",
      " |  params\n",
      " |      Get the parameters and the actual/default values only.\n",
      " |      \n",
      " |      :returns: A dictionary of parameters used to build this model.\n",
      " |  \n",
      " |  type\n",
      " |      Get the type of model built as a string.\n",
      " |      \n",
      " |      :returns: \"classifier\" or \"regressor\" or \"unsupervised\"\n",
      " |  \n",
      " |  xvals\n",
      " |      Return a list of the cross-validated models.\n",
      " |      \n",
      " |      :returns: A list of models\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __getattr__(self, item)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from h2o.utils.backward_compatibility.BackwardsCompatibleBase:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(H2OGeneralizedLinearEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
