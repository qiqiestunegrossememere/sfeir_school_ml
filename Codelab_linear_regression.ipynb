{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "=============\n",
    "\n",
    "Assignment 1\n",
    "------------\n",
    "\n",
    "The objective of this assignment is to learn how to apply a linear regression algorithm on the iris data set.\n",
    "\n",
    "This notebook uses the [iris](https://archive.ics.uci.edu/ml/datasets/Iris) dataset to be used with python experiments. This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "First we would like to load this data set and visulasation the distribution using the two first two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target_names', 'data', 'target', 'DESCR', 'feature_names']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAFsCAYAAACEtRP5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHOz/AGUMDlIHrRlMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1072b40d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "print iris.keys()\n",
    "print target_names\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 2].min() - .5, X[:, 2].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 2], c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[2])\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we would like to predict the length of petal by using the length of sepal. In this case, the \"sepal length\" is the input value and the \"petal length\" is the target value. In order to apply the Machine Learning algotirthm in the h2o, first we need to import the H2o library and initialization the H2o flow. See the installation document, if the \"h2o\" is not installed in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function init in module h2o.h2o:\n",
      "\n",
      "init(url=None, ip=None, port=None, https=None, insecure=False, username=None, password=None, cluster_name=None, proxy=None, start_h2o=True, nthreads=-1, ice_root=None, enable_assertions=True, max_mem_size=None, min_mem_size=None, strict_version_check=True, **kwargs)\n",
      "    Attempt to connect to a local server, or if not successful start a new server and connect to it.\n",
      "    \n",
      "    :param url:\n",
      "    :param ip:\n",
      "    :param port:\n",
      "    :param https:\n",
      "    :param insecure:\n",
      "    :param username:\n",
      "    :param password:\n",
      "    :param cluster_name:\n",
      "    :param proxy:\n",
      "    :param start_h2o:\n",
      "    :param nthreads:\n",
      "    :param ice_root:\n",
      "    :param enable_assertions:\n",
      "    :param max_mem_size:\n",
      "    :param min_mem_size:\n",
      "    :param strict_version_check:\n",
      "    :param kwargs: (all other deprecated attributes)\n",
      "    :returns: nothing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "#Use help to get the details of the using function\n",
    "help(h2o.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything works, an H2o instance will be lanunch at http://localhost:54321. By taping this adress in your web browser, we can observe that the H2o Web UI is in place. We can directly develop the ML algorithm by using the Web UI. But for this assignment, we use the H2o's API for python.\n",
    "![title](./h2o_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo is provided by H2o, you can also entre \"h2o.demo(\"glm\")\" to run this demo in your console. The demo is for a classification problem, but the principale remains the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Upload the prostate dataset\n",
    "prostate =  h2o.import_file(path=\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/logreg/prostate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>ID           </th><th>CAPSULE       </th><th>AGE          </th><th>RACE          </th><th>DPROS        </th><th>DCAPS         </th><th>PSA          </th><th>VOL          </th><th>GLEASON      </th></tr>\n",
       "<tr><td>type   </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>real         </td><td>real         </td><td>int          </td></tr>\n",
       "<tr><td>mins   </td><td>1.0          </td><td>0.0           </td><td>43.0         </td><td>0.0           </td><td>1.0          </td><td>1.0           </td><td>0.3          </td><td>0.0          </td><td>0.0          </td></tr>\n",
       "<tr><td>mean   </td><td>190.5        </td><td>0.402631578947</td><td>66.0394736842</td><td>1.08684210526 </td><td>2.27105263158</td><td>1.10789473684 </td><td>15.4086315789</td><td>15.8129210526</td><td>6.38421052632</td></tr>\n",
       "<tr><td>maxs   </td><td>380.0        </td><td>1.0           </td><td>79.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>139.7        </td><td>97.6         </td><td>9.0          </td></tr>\n",
       "<tr><td>sigma  </td><td>109.840793879</td><td>0.491074338963</td><td>6.52707126917</td><td>0.308773258025</td><td>1.00010761815</td><td>0.310656449351</td><td>19.9975726686</td><td>18.3476199673</td><td>1.09195337443</td></tr>\n",
       "<tr><td>zeros  </td><td>0            </td><td>227           </td><td>0            </td><td>3             </td><td>0            </td><td>0             </td><td>0            </td><td>167          </td><td>2            </td></tr>\n",
       "<tr><td>missing</td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0            </td><td>0            </td></tr>\n",
       "<tr><td>0      </td><td>1.0          </td><td>0.0           </td><td>65.0         </td><td>1.0           </td><td>2.0          </td><td>1.0           </td><td>1.4          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>1      </td><td>2.0          </td><td>0.0           </td><td>72.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>6.7          </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>2      </td><td>3.0          </td><td>0.0           </td><td>70.0         </td><td>1.0           </td><td>1.0          </td><td>2.0           </td><td>4.9          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>3      </td><td>4.0          </td><td>0.0           </td><td>76.0         </td><td>2.0           </td><td>2.0          </td><td>1.0           </td><td>51.2         </td><td>20.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>4      </td><td>5.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>12.3         </td><td>55.9         </td><td>6.0          </td></tr>\n",
       "<tr><td>5      </td><td>6.0          </td><td>1.0           </td><td>71.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>3.3          </td><td>0.0          </td><td>8.0          </td></tr>\n",
       "<tr><td>6      </td><td>7.0          </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>31.9         </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>7      </td><td>8.0          </td><td>0.0           </td><td>61.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>66.7         </td><td>27.2         </td><td>7.0          </td></tr>\n",
       "<tr><td>8      </td><td>9.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>3.9          </td><td>24.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>9      </td><td>10.0         </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>1.0          </td><td>2.0           </td><td>13.0         </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a description of the prostate data\n",
    "prostate.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split the dataset into ~70/30, training/test sets\n",
    "r = prostate[0].runif()\n",
    "train = prostate[r < 0.70]\n",
    "test = prostate[r >= 0.70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response columns to factors (for binary classification problems)\n",
    "train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n",
    "test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Build a (classification) GLM\n",
    "from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "prostate_glm = H2OGeneralizedLinearEstimator(family=\"binomial\", alpha=[0.5])\n",
    "prostate_glm.train(x=[\"AGE\", \"RACE\", \"PSA\", \"VOL\", \"GLEASON\"],y=\"CAPSULE\", training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1473863160481_1\n",
      "GLM Model: summary\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>family</b></td>\n",
       "<td><b>link</b></td>\n",
       "<td><b>regularization</b></td>\n",
       "<td><b>number_of_predictors_total</b></td>\n",
       "<td><b>number_of_active_predictors</b></td>\n",
       "<td><b>number_of_iterations</b></td>\n",
       "<td><b>training_frame</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>binomial</td>\n",
       "<td>logit</td>\n",
       "<td>Elastic Net (alpha = 0.5, lambda = 4.568E-4 )</td>\n",
       "<td>5</td>\n",
       "<td>5</td>\n",
       "<td>4</td>\n",
       "<td>py_4_sid_9b2d</td></tr></table></div>"
      ],
      "text/plain": [
       "    family    link    regularization                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
       "--  --------  ------  ---------------------------------------------  ----------------------------  -----------------------------  ----------------------  ----------------\n",
       "    binomial  logit   Elastic Net (alpha = 0.5, lambda = 4.568E-4 )  5                             5                              4                       py_4_sid_9b2d"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.169958131122\n",
      "RMSE: 0.412259785962\n",
      "LogLoss: 0.509714211113\n",
      "Null degrees of freedom: 271\n",
      "Residual degrees of freedom: 266\n",
      "Null deviance: 362.814717185\n",
      "Residual deviance: 277.284530845\n",
      "AIC: 289.284530845\n",
      "AUC: 0.806900484745\n",
      "Gini: 0.61380096949\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.259956270067: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>101.0</td>\n",
       "<td>66.0</td>\n",
       "<td>0.3952</td>\n",
       "<td> (66.0/167.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>14.0</td>\n",
       "<td>91.0</td>\n",
       "<td>0.1333</td>\n",
       "<td> (14.0/105.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>115.0</td>\n",
       "<td>157.0</td>\n",
       "<td>0.2941</td>\n",
       "<td> (80.0/272.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      101  66   0.3952   (66.0/167.0)\n",
       "1      14   91   0.1333   (14.0/105.0)\n",
       "Total  115  157  0.2941   (80.0/272.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2599563</td>\n",
       "<td>0.6946565</td>\n",
       "<td>155.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1561095</td>\n",
       "<td>0.7898894</td>\n",
       "<td>211.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5222905</td>\n",
       "<td>0.7093822</td>\n",
       "<td>81.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4654549</td>\n",
       "<td>0.7683824</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9740674</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0787324</td>\n",
       "<td>1.0</td>\n",
       "<td>251.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9740674</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4654549</td>\n",
       "<td>0.5074081</td>\n",
       "<td>98.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3788144</td>\n",
       "<td>0.7305389</td>\n",
       "<td>120.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4654549</td>\n",
       "<td>0.7512689</td>\n",
       "<td>98.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.259956     0.694656  155\n",
       "max f2                       0.156109     0.789889  211\n",
       "max f0point5                 0.52229      0.709382  81\n",
       "max accuracy                 0.465455     0.768382  98\n",
       "max precision                0.974067     1         0\n",
       "max recall                   0.0787324    1         251\n",
       "max specificity              0.974067     1         0\n",
       "max absolute_mcc             0.465455     0.507408  98\n",
       "max min_per_class_accuracy   0.378814     0.730539  120\n",
       "max mean_per_class_accuracy  0.465455     0.751269  98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 38.60 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0110294</td>\n",
       "<td>0.9701192</td>\n",
       "<td>2.5904762</td>\n",
       "<td>2.5904762</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0285714</td>\n",
       "<td>159.0476190</td>\n",
       "<td>159.0476190</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0220588</td>\n",
       "<td>0.9584342</td>\n",
       "<td>2.5904762</td>\n",
       "<td>2.5904762</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0571429</td>\n",
       "<td>159.0476190</td>\n",
       "<td>159.0476190</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0330882</td>\n",
       "<td>0.9420198</td>\n",
       "<td>2.5904762</td>\n",
       "<td>2.5904762</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.0857143</td>\n",
       "<td>159.0476190</td>\n",
       "<td>159.0476190</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0404412</td>\n",
       "<td>0.9175647</td>\n",
       "<td>2.5904762</td>\n",
       "<td>2.5904762</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0190476</td>\n",
       "<td>0.1047619</td>\n",
       "<td>159.0476190</td>\n",
       "<td>159.0476190</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0514706</td>\n",
       "<td>0.9095522</td>\n",
       "<td>2.5904762</td>\n",
       "<td>2.5904762</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.1333333</td>\n",
       "<td>159.0476190</td>\n",
       "<td>159.0476190</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1029412</td>\n",
       "<td>0.8000035</td>\n",
       "<td>2.2204082</td>\n",
       "<td>2.4054422</td>\n",
       "<td>0.8571429</td>\n",
       "<td>0.9285714</td>\n",
       "<td>0.1142857</td>\n",
       "<td>0.2476190</td>\n",
       "<td>122.0408163</td>\n",
       "<td>140.5442177</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1507353</td>\n",
       "<td>0.6610781</td>\n",
       "<td>1.5941392</td>\n",
       "<td>2.1481998</td>\n",
       "<td>0.6153846</td>\n",
       "<td>0.8292683</td>\n",
       "<td>0.0761905</td>\n",
       "<td>0.3238095</td>\n",
       "<td>59.4139194</td>\n",
       "<td>114.8199768</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2022059</td>\n",
       "<td>0.5992124</td>\n",
       "<td>1.2952381</td>\n",
       "<td>1.9310823</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7454545</td>\n",
       "<td>0.0666667</td>\n",
       "<td>0.3904762</td>\n",
       "<td>29.5238095</td>\n",
       "<td>93.1082251</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3014706</td>\n",
       "<td>0.5284014</td>\n",
       "<td>1.9188713</td>\n",
       "<td>1.9270616</td>\n",
       "<td>0.7407407</td>\n",
       "<td>0.7439024</td>\n",
       "<td>0.1904762</td>\n",
       "<td>0.5809524</td>\n",
       "<td>91.8871252</td>\n",
       "<td>92.7061556</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4007353</td>\n",
       "<td>0.4307599</td>\n",
       "<td>1.0553792</td>\n",
       "<td>1.7111402</td>\n",
       "<td>0.4074074</td>\n",
       "<td>0.6605505</td>\n",
       "<td>0.1047619</td>\n",
       "<td>0.6857143</td>\n",
       "<td>5.5379189</td>\n",
       "<td>71.1140236</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3102846</td>\n",
       "<td>0.9594356</td>\n",
       "<td>1.5619048</td>\n",
       "<td>0.3703704</td>\n",
       "<td>0.6029412</td>\n",
       "<td>0.0952381</td>\n",
       "<td>0.7809524</td>\n",
       "<td>-4.0564374</td>\n",
       "<td>56.1904762</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5992647</td>\n",
       "<td>0.2507280</td>\n",
       "<td>0.9594356</td>\n",
       "<td>1.4621093</td>\n",
       "<td>0.3703704</td>\n",
       "<td>0.5644172</td>\n",
       "<td>0.0952381</td>\n",
       "<td>0.8761905</td>\n",
       "<td>-4.0564374</td>\n",
       "<td>46.2109261</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6985294</td>\n",
       "<td>0.2041036</td>\n",
       "<td>0.1918871</td>\n",
       "<td>1.2816040</td>\n",
       "<td>0.0740741</td>\n",
       "<td>0.4947368</td>\n",
       "<td>0.0190476</td>\n",
       "<td>0.8952381</td>\n",
       "<td>-80.8112875</td>\n",
       "<td>28.1604010</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7977941</td>\n",
       "<td>0.1457916</td>\n",
       "<td>0.5756614</td>\n",
       "<td>1.1937678</td>\n",
       "<td>0.2222222</td>\n",
       "<td>0.4608295</td>\n",
       "<td>0.0571429</td>\n",
       "<td>0.9523810</td>\n",
       "<td>-42.4338624</td>\n",
       "<td>19.3767830</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8970588</td>\n",
       "<td>0.0862184</td>\n",
       "<td>0.2878307</td>\n",
       "<td>1.0935207</td>\n",
       "<td>0.1111111</td>\n",
       "<td>0.4221311</td>\n",
       "<td>0.0285714</td>\n",
       "<td>0.9809524</td>\n",
       "<td>-71.2169312</td>\n",
       "<td>9.3520687</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0005437</td>\n",
       "<td>0.1850340</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.3860294</td>\n",
       "<td>0.0190476</td>\n",
       "<td>1.0</td>\n",
       "<td>-81.4965986</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0110294                   0.970119           2.59048   2.59048            1                1                           0.0285714       0.0285714                  159.048   159.048\n",
       "    2        0.0220588                   0.958434           2.59048   2.59048            1                1                           0.0285714       0.0571429                  159.048   159.048\n",
       "    3        0.0330882                   0.94202            2.59048   2.59048            1                1                           0.0285714       0.0857143                  159.048   159.048\n",
       "    4        0.0404412                   0.917565           2.59048   2.59048            1                1                           0.0190476       0.104762                   159.048   159.048\n",
       "    5        0.0514706                   0.909552           2.59048   2.59048            1                1                           0.0285714       0.133333                   159.048   159.048\n",
       "    6        0.102941                    0.800003           2.22041   2.40544            0.857143         0.928571                    0.114286        0.247619                   122.041   140.544\n",
       "    7        0.150735                    0.661078           1.59414   2.1482             0.615385         0.829268                    0.0761905       0.32381                    59.4139   114.82\n",
       "    8        0.202206                    0.599212           1.29524   1.93108            0.5              0.745455                    0.0666667       0.390476                   29.5238   93.1082\n",
       "    9        0.301471                    0.528401           1.91887   1.92706            0.740741         0.743902                    0.190476        0.580952                   91.8871   92.7062\n",
       "    10       0.400735                    0.43076            1.05538   1.71114            0.407407         0.66055                     0.104762        0.685714                   5.53792   71.114\n",
       "    11       0.5                         0.310285           0.959436  1.5619             0.37037          0.602941                    0.0952381       0.780952                   -4.05644  56.1905\n",
       "    12       0.599265                    0.250728           0.959436  1.46211            0.37037          0.564417                    0.0952381       0.87619                    -4.05644  46.2109\n",
       "    13       0.698529                    0.204104           0.191887  1.2816             0.0740741        0.494737                    0.0190476       0.895238                   -80.8113  28.1604\n",
       "    14       0.797794                    0.145792           0.575661  1.19377            0.222222         0.460829                    0.0571429       0.952381                   -42.4339  19.3768\n",
       "    15       0.897059                    0.0862184          0.287831  1.09352            0.111111         0.422131                    0.0285714       0.980952                   -71.2169  9.35207\n",
       "    16       1                           0.000543735        0.185034  1                  0.0714286        0.386029                    0.0190476       1                          -81.4966  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iteration</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 16:26:46</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>181.4073586</td>\n",
       "<td>0.6669388</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 16:26:46</td>\n",
       "<td> 0.149 sec</td>\n",
       "<td>1</td>\n",
       "<td>141.7261113</td>\n",
       "<td>0.5215234</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 16:26:46</td>\n",
       "<td> 0.206 sec</td>\n",
       "<td>2</td>\n",
       "<td>138.7514854</td>\n",
       "<td>0.5108072</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 16:26:46</td>\n",
       "<td> 0.379 sec</td>\n",
       "<td>3</td>\n",
       "<td>138.6430449</td>\n",
       "<td>0.5104629</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 16:26:46</td>\n",
       "<td> 0.414 sec</td>\n",
       "<td>4</td>\n",
       "<td>138.6422654</td>\n",
       "<td>0.5104623</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iteration    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  -----------  -------------------------  -----------\n",
       "    2016-09-14 16:26:46  0.000 sec   0            181.407                    0.666939\n",
       "    2016-09-14 16:26:46  0.149 sec   1            141.726                    0.521523\n",
       "    2016-09-14 16:26:46  0.206 sec   2            138.751                    0.510807\n",
       "    2016-09-14 16:26:46  0.379 sec   3            138.643                    0.510463\n",
       "    2016-09-14 16:26:46  0.414 sec   4            138.642                    0.510462"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the model\n",
    "prostate_glm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">       p0</th><th style=\"text-align: right;\">      p1</th></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.748326 </td><td style=\"text-align: right;\">0.251674</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.483653 </td><td style=\"text-align: right;\">0.516347</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.66234  </td><td style=\"text-align: right;\">0.33766 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0706839</td><td style=\"text-align: right;\">0.929316</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.268231 </td><td style=\"text-align: right;\">0.731769</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.680086 </td><td style=\"text-align: right;\">0.319914</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.706691 </td><td style=\"text-align: right;\">0.293309</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.746281 </td><td style=\"text-align: right;\">0.253719</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.534124 </td><td style=\"text-align: right;\">0.465876</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.813918 </td><td style=\"text-align: right;\">0.186082</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test set and show the first ten predictions\n",
    "predictions = prostate_glm.predict(test)\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.198326712222\n",
      "RMSE: 0.445338873469\n",
      "LogLoss: 0.569896286647\n",
      "Null degrees of freedom: 107\n",
      "Residual degrees of freedom: 102\n",
      "Null deviance: 149.913795215\n",
      "Residual deviance: 123.097597916\n",
      "AIC: 135.097597916\n",
      "AUC: 0.761458333333\n",
      "Gini: 0.522916666667\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.214166807007: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>28.0</td>\n",
       "<td>32.0</td>\n",
       "<td>0.5333</td>\n",
       "<td> (32.0/60.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>4.0</td>\n",
       "<td>44.0</td>\n",
       "<td>0.0833</td>\n",
       "<td> (4.0/48.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>32.0</td>\n",
       "<td>76.0</td>\n",
       "<td>0.3333</td>\n",
       "<td> (36.0/108.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      28   32   0.5333   (32.0/60.0)\n",
       "1      4    44   0.0833   (4.0/48.0)\n",
       "Total  32   76   0.3333   (36.0/108.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2141668</td>\n",
       "<td>0.7096774</td>\n",
       "<td>75.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1738349</td>\n",
       "<td>0.8333333</td>\n",
       "<td>83.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5678743</td>\n",
       "<td>0.6640625</td>\n",
       "<td>19.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4511959</td>\n",
       "<td>0.6944444</td>\n",
       "<td>40.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9957221</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0930112</td>\n",
       "<td>1.0</td>\n",
       "<td>96.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9957221</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2141668</td>\n",
       "<td>0.4171488</td>\n",
       "<td>75.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3656544</td>\n",
       "<td>0.6666667</td>\n",
       "<td>50.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2728415</td>\n",
       "<td>0.7041667</td>\n",
       "<td>60.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.214167     0.709677  75\n",
       "max f2                       0.173835     0.833333  83\n",
       "max f0point5                 0.567874     0.664062  19\n",
       "max accuracy                 0.451196     0.694444  40\n",
       "max precision                0.995722     1         0\n",
       "max recall                   0.0930112    1         96\n",
       "max specificity              0.995722     1         0\n",
       "max absolute_mcc             0.214167     0.417149  75\n",
       "max min_per_class_accuracy   0.365654     0.666667  50\n",
       "max mean_per_class_accuracy  0.272841     0.704167  60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 44.44 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0185185</td>\n",
       "<td>0.9532189</td>\n",
       "<td>2.25</td>\n",
       "<td>2.25</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.0416667</td>\n",
       "<td>125.0</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0277778</td>\n",
       "<td>0.9281842</td>\n",
       "<td>2.25</td>\n",
       "<td>2.25</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.0625</td>\n",
       "<td>125.0</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0370370</td>\n",
       "<td>0.9181928</td>\n",
       "<td>2.25</td>\n",
       "<td>2.25</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.0833333</td>\n",
       "<td>125.0</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0462963</td>\n",
       "<td>0.9002893</td>\n",
       "<td>2.25</td>\n",
       "<td>2.25</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.1041667</td>\n",
       "<td>125.0</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0555556</td>\n",
       "<td>0.8831005</td>\n",
       "<td>2.25</td>\n",
       "<td>2.25</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0208333</td>\n",
       "<td>0.125</td>\n",
       "<td>125.0</td>\n",
       "<td>125.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1018519</td>\n",
       "<td>0.7493004</td>\n",
       "<td>1.8</td>\n",
       "<td>2.0454545</td>\n",
       "<td>0.8</td>\n",
       "<td>0.9090909</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.2083333</td>\n",
       "<td>80.0</td>\n",
       "<td>104.5454545</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1574074</td>\n",
       "<td>0.6097791</td>\n",
       "<td>1.5</td>\n",
       "<td>1.8529412</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.8235294</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.2916667</td>\n",
       "<td>50.0</td>\n",
       "<td>85.2941176</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2037037</td>\n",
       "<td>0.5579870</td>\n",
       "<td>1.8</td>\n",
       "<td>1.8409091</td>\n",
       "<td>0.8</td>\n",
       "<td>0.8181818</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.375</td>\n",
       "<td>80.0</td>\n",
       "<td>84.0909091</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3055556</td>\n",
       "<td>0.4993527</td>\n",
       "<td>0.6136364</td>\n",
       "<td>1.4318182</td>\n",
       "<td>0.2727273</td>\n",
       "<td>0.6363636</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.4375</td>\n",
       "<td>-38.6363636</td>\n",
       "<td>43.1818182</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.3981481</td>\n",
       "<td>0.4165220</td>\n",
       "<td>1.575</td>\n",
       "<td>1.4651163</td>\n",
       "<td>0.7</td>\n",
       "<td>0.6511628</td>\n",
       "<td>0.1458333</td>\n",
       "<td>0.5833333</td>\n",
       "<td>57.5</td>\n",
       "<td>46.5116279</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3299489</td>\n",
       "<td>1.2272727</td>\n",
       "<td>1.4166667</td>\n",
       "<td>0.5454545</td>\n",
       "<td>0.6296296</td>\n",
       "<td>0.125</td>\n",
       "<td>0.7083333</td>\n",
       "<td>22.7272727</td>\n",
       "<td>41.6666667</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6018519</td>\n",
       "<td>0.2541968</td>\n",
       "<td>0.8181818</td>\n",
       "<td>1.3153846</td>\n",
       "<td>0.3636364</td>\n",
       "<td>0.5846154</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.7916667</td>\n",
       "<td>-18.1818182</td>\n",
       "<td>31.5384615</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.6944444</td>\n",
       "<td>0.2147971</td>\n",
       "<td>1.125</td>\n",
       "<td>1.29</td>\n",
       "<td>0.5</td>\n",
       "<td>0.5733333</td>\n",
       "<td>0.1041667</td>\n",
       "<td>0.8958333</td>\n",
       "<td>12.5</td>\n",
       "<td>29.0</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7962963</td>\n",
       "<td>0.1619701</td>\n",
       "<td>0.6136364</td>\n",
       "<td>1.2034884</td>\n",
       "<td>0.2727273</td>\n",
       "<td>0.5348837</td>\n",
       "<td>0.0625</td>\n",
       "<td>0.9583333</td>\n",
       "<td>-38.6363636</td>\n",
       "<td>20.3488372</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8981481</td>\n",
       "<td>0.0928423</td>\n",
       "<td>0.4090909</td>\n",
       "<td>1.1134021</td>\n",
       "<td>0.1818182</td>\n",
       "<td>0.4948454</td>\n",
       "<td>0.0416667</td>\n",
       "<td>1.0</td>\n",
       "<td>-59.0909091</td>\n",
       "<td>11.3402062</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0004794</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.4444444</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0185185                   0.953219           2.25      2.25               1                1                           0.0416667       0.0416667                  125       125\n",
       "    2        0.0277778                   0.928184           2.25      2.25               1                1                           0.0208333       0.0625                     125       125\n",
       "    3        0.037037                    0.918193           2.25      2.25               1                1                           0.0208333       0.0833333                  125       125\n",
       "    4        0.0462963                   0.900289           2.25      2.25               1                1                           0.0208333       0.104167                   125       125\n",
       "    5        0.0555556                   0.8831             2.25      2.25               1                1                           0.0208333       0.125                      125       125\n",
       "    6        0.101852                    0.7493             1.8       2.04545            0.8              0.909091                    0.0833333       0.208333                   80        104.545\n",
       "    7        0.157407                    0.609779           1.5       1.85294            0.666667         0.823529                    0.0833333       0.291667                   50        85.2941\n",
       "    8        0.203704                    0.557987           1.8       1.84091            0.8              0.818182                    0.0833333       0.375                      80        84.0909\n",
       "    9        0.305556                    0.499353           0.613636  1.43182            0.272727         0.636364                    0.0625          0.4375                     -38.6364  43.1818\n",
       "    10       0.398148                    0.416522           1.575     1.46512            0.7              0.651163                    0.145833        0.583333                   57.5      46.5116\n",
       "    11       0.5                         0.329949           1.22727   1.41667            0.545455         0.62963                     0.125           0.708333                   22.7273   41.6667\n",
       "    12       0.601852                    0.254197           0.818182  1.31538            0.363636         0.584615                    0.0833333       0.791667                   -18.1818  31.5385\n",
       "    13       0.694444                    0.214797           1.125     1.29               0.5              0.573333                    0.104167        0.895833                   12.5      29\n",
       "    14       0.796296                    0.16197            0.613636  1.20349            0.272727         0.534884                    0.0625          0.958333                   -38.6364  20.3488\n",
       "    15       0.898148                    0.0928423          0.409091  1.1134             0.181818         0.494845                    0.0416667       1                          -59.0909  11.3402\n",
       "    16       1                           0.000479448        0         1                  0                0.444444                    0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Show default performance metrics\n",
    "performance = prostate_glm.model_performance(test)\n",
    "performance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "------------\n",
    "Please convert your demo for the iris data set. First we need to merge the input and the target into a data frame. In this assignment, we would like to predict the length of petal by using the length of sepal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3  target\n",
      "0  5.1  3.5  1.4  0.2       0\n",
      "1  4.9  3.0  1.4  0.2       0\n",
      "2  4.7  3.2  1.3  0.2       0\n",
      "3  4.6  3.1  1.5  0.2       0\n",
      "4  5.0  3.6  1.4  0.2       0\n",
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df=pd.DataFrame(X)\n",
    "iris_df.insert(4,\"target\",pd.DataFrame(y))\n",
    "print iris_df.head()\n",
    "iris_h2o=h2o.H2OFrame(iris_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>C1            </th><th>C2            </th><th>C3           </th><th>C4            </th><th>C5            </th></tr>\n",
       "<tr><td>type   </td><td>real          </td><td>real          </td><td>real         </td><td>real          </td><td>int           </td></tr>\n",
       "<tr><td>mins   </td><td>4.3           </td><td>2.0           </td><td>1.0          </td><td>0.1           </td><td>0.0           </td></tr>\n",
       "<tr><td>mean   </td><td>5.84333333333 </td><td>3.054         </td><td>3.75866666667</td><td>1.19866666667 </td><td>1.0           </td></tr>\n",
       "<tr><td>maxs   </td><td>7.9           </td><td>4.4           </td><td>6.9          </td><td>2.5           </td><td>2.0           </td></tr>\n",
       "<tr><td>sigma  </td><td>0.828066127978</td><td>0.433594311362</td><td>1.76442041995</td><td>0.763160741701</td><td>0.819231920519</td></tr>\n",
       "<tr><td>zeros  </td><td>0             </td><td>0             </td><td>0            </td><td>0             </td><td>50            </td></tr>\n",
       "<tr><td>missing</td><td>0             </td><td>0             </td><td>0            </td><td>0             </td><td>0             </td></tr>\n",
       "<tr><td>0      </td><td>5.1           </td><td>3.5           </td><td>1.4          </td><td>0.2           </td><td>0.0           </td></tr>\n",
       "<tr><td>1      </td><td>4.9           </td><td>3.0           </td><td>1.4          </td><td>0.2           </td><td>0.0           </td></tr>\n",
       "<tr><td>2      </td><td>4.7           </td><td>3.2           </td><td>1.3          </td><td>0.2           </td><td>0.0           </td></tr>\n",
       "<tr><td>3      </td><td>4.6           </td><td>3.1           </td><td>1.5          </td><td>0.2           </td><td>0.0           </td></tr>\n",
       "<tr><td>4      </td><td>5.0           </td><td>3.6           </td><td>1.4          </td><td>0.2           </td><td>0.0           </td></tr>\n",
       "<tr><td>5      </td><td>5.4           </td><td>3.9           </td><td>1.7          </td><td>0.4           </td><td>0.0           </td></tr>\n",
       "<tr><td>6      </td><td>4.6           </td><td>3.4           </td><td>1.4          </td><td>0.3           </td><td>0.0           </td></tr>\n",
       "<tr><td>7      </td><td>5.0           </td><td>3.4           </td><td>1.5          </td><td>0.2           </td><td>0.0           </td></tr>\n",
       "<tr><td>8      </td><td>4.4           </td><td>2.9           </td><td>1.4          </td><td>0.2           </td><td>0.0           </td></tr>\n",
       "<tr><td>9      </td><td>4.9           </td><td>3.1           </td><td>1.5          </td><td>0.1           </td><td>0.0           </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_h2o.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the colname of h2o data frame is lost, to get a better understand of your data frame you can reset the colnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>sepal length (cm)  </th><th>sepal width (cm)  </th><th>petal length (cm)  </th><th>petal width (cm)  </th><th>target        </th></tr>\n",
       "<tr><td>type   </td><td>real               </td><td>real              </td><td>real               </td><td>real              </td><td>int           </td></tr>\n",
       "<tr><td>mins   </td><td>4.3                </td><td>2.0               </td><td>1.0                </td><td>0.1               </td><td>0.0           </td></tr>\n",
       "<tr><td>mean   </td><td>5.84333333333      </td><td>3.054             </td><td>3.75866666667      </td><td>1.19866666667     </td><td>1.0           </td></tr>\n",
       "<tr><td>maxs   </td><td>7.9                </td><td>4.4               </td><td>6.9                </td><td>2.5               </td><td>2.0           </td></tr>\n",
       "<tr><td>sigma  </td><td>0.828066127978     </td><td>0.433594311362    </td><td>1.76442041995      </td><td>0.763160741701    </td><td>0.819231920519</td></tr>\n",
       "<tr><td>zeros  </td><td>0                  </td><td>0                 </td><td>0                  </td><td>0                 </td><td>50            </td></tr>\n",
       "<tr><td>missing</td><td>0                  </td><td>0                 </td><td>0                  </td><td>0                 </td><td>0             </td></tr>\n",
       "<tr><td>0      </td><td>5.1                </td><td>3.5               </td><td>1.4                </td><td>0.2               </td><td>0.0           </td></tr>\n",
       "<tr><td>1      </td><td>4.9                </td><td>3.0               </td><td>1.4                </td><td>0.2               </td><td>0.0           </td></tr>\n",
       "<tr><td>2      </td><td>4.7                </td><td>3.2               </td><td>1.3                </td><td>0.2               </td><td>0.0           </td></tr>\n",
       "<tr><td>3      </td><td>4.6                </td><td>3.1               </td><td>1.5                </td><td>0.2               </td><td>0.0           </td></tr>\n",
       "<tr><td>4      </td><td>5.0                </td><td>3.6               </td><td>1.4                </td><td>0.2               </td><td>0.0           </td></tr>\n",
       "<tr><td>5      </td><td>5.4                </td><td>3.9               </td><td>1.7                </td><td>0.4               </td><td>0.0           </td></tr>\n",
       "<tr><td>6      </td><td>4.6                </td><td>3.4               </td><td>1.4                </td><td>0.3               </td><td>0.0           </td></tr>\n",
       "<tr><td>7      </td><td>5.0                </td><td>3.4               </td><td>1.5                </td><td>0.2               </td><td>0.0           </td></tr>\n",
       "<tr><td>8      </td><td>4.4                </td><td>2.9               </td><td>1.4                </td><td>0.2               </td><td>0.0           </td></tr>\n",
       "<tr><td>9      </td><td>4.9                </td><td>3.1               </td><td>1.5                </td><td>0.1               </td><td>0.0           </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris.feature_names.append(\"target\")\n",
    "print iris.feature_names\n",
    "iris_h2o.set_names(iris.feature_names)\n",
    "\n",
    "iris_h2o.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that our problem is a regression problem. \n",
    "Using help() to give a more details of the H2OGeneralizedLinearEstimator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split the dataset into ~70/30, training/test sets\n",
    "r = iris_h2o[0].runif()\n",
    "iris_train = iris_h2o[r < 0.70]\n",
    "iris_test = iris_h2o[r >= 0.70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(H2OGeneralizedLinearEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
