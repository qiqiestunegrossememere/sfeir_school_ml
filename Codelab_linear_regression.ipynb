{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression\n",
    "=============\n",
    "\n",
    "Assignment 1\n",
    "------------\n",
    "\n",
    "The objective of this assignment is to learn how to apply a linear regression algorithm on the iris data set.\n",
    "\n",
    "This notebook uses the [iris](https://archive.ics.uci.edu/ml/datasets/Iris) dataset to be used with python experiments. This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. (See Duda & Hart, for example.) The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows being the samples and the columns being: Sepal Length, Sepal Width, Petal Length and Petal Width.\n",
    "First we would like to load this data set and visulasation the distribution using the two first two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['target_names', 'data', 'target', 'DESCR', 'feature_names']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([], <a list of 0 Text yticklabel objects>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdsAAAFsCAYAAACEtRP5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHOz/AGUMDlIHrRlMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a5f6690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "target_names = iris.target_names\n",
    "print iris.keys()\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 2].min() - .5, X[:, 2].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 2], c=y, cmap=plt.cm.Paired)\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[2])\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we would like to predict the length of petal by using the length of sepal. In this case, the \"sepal length\" is the input value and the \"petal length\" is the target value. In order to apply the Machine Learning algotirthm in the h2o, first we need to import the H2o library and initialization the H2o flow. See the installation document, if the \"h2o\" is not installed in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function init in module h2o.h2o:\n",
      "\n",
      "init(url=None, ip=None, port=None, https=None, insecure=False, username=None, password=None, cluster_name=None, proxy=None, start_h2o=True, nthreads=-1, ice_root=None, enable_assertions=True, max_mem_size=None, min_mem_size=None, strict_version_check=True, **kwargs)\n",
      "    Attempt to connect to a local server, or if not successful start a new server and connect to it.\n",
      "    \n",
      "    :param url:\n",
      "    :param ip:\n",
      "    :param port:\n",
      "    :param https:\n",
      "    :param insecure:\n",
      "    :param username:\n",
      "    :param password:\n",
      "    :param cluster_name:\n",
      "    :param proxy:\n",
      "    :param start_h2o:\n",
      "    :param nthreads:\n",
      "    :param ice_root:\n",
      "    :param enable_assertions:\n",
      "    :param max_mem_size:\n",
      "    :param min_mem_size:\n",
      "    :param strict_version_check:\n",
      "    :param kwargs: (all other deprecated attributes)\n",
      "    :returns: nothing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import h2o\n",
    "#Use help to get the details of the using function\n",
    "help(h2o.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_101\"; Java(TM) SE Runtime Environment (build 1.8.0_101-b13); Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)\n",
      "  Starting server from /usr/local/h2o_jar/h2o.jar\n",
      "  Ice root: /var/folders/dy/n8yy2ljj7qs1knmcrf70fsqw0000gq/T/tmp7nY6B1\n",
      "  JVM stdout: /var/folders/dy/n8yy2ljj7qs1knmcrf70fsqw0000gq/T/tmp7nY6B1/h2o_jiqiongqiu_started_from_python.out\n",
      "  JVM stderr: /var/folders/dy/n8yy2ljj7qs1knmcrf70fsqw0000gq/T/tmp7nY6B1/h2o_jiqiongqiu_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    }
   ],
   "source": [
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything works, an H2o instance will be lanunch at http://localhost:54321. By taping this adress in your web browser, we can observe that the H2o Web UI is in place. We can directly develop the ML algorithm by using the Web UI. But for this assignment, we use the H2o's API for python.\n",
    "![title](./h2o_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo is provided by H2o, you can also entre \"h2o.demo(\"glm\")\" to run this demo in your console. The demo is for a classification problem, but the principale remains the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Upload the prostate dataset\n",
    "prostate =  h2o.import_file(path=\"https://h2o-public-test-data.s3.amazonaws.com/smalldata/logreg/prostate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>ID           </th><th>CAPSULE       </th><th>AGE          </th><th>RACE          </th><th>DPROS        </th><th>DCAPS         </th><th>PSA          </th><th>VOL          </th><th>GLEASON      </th></tr>\n",
       "<tr><td>type   </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>int          </td><td>int           </td><td>real         </td><td>real         </td><td>int          </td></tr>\n",
       "<tr><td>mins   </td><td>1.0          </td><td>0.0           </td><td>43.0         </td><td>0.0           </td><td>1.0          </td><td>1.0           </td><td>0.3          </td><td>0.0          </td><td>0.0          </td></tr>\n",
       "<tr><td>mean   </td><td>190.5        </td><td>0.402631578947</td><td>66.0394736842</td><td>1.08684210526 </td><td>2.27105263158</td><td>1.10789473684 </td><td>15.4086315789</td><td>15.8129210526</td><td>6.38421052632</td></tr>\n",
       "<tr><td>maxs   </td><td>380.0        </td><td>1.0           </td><td>79.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>139.7        </td><td>97.6         </td><td>9.0          </td></tr>\n",
       "<tr><td>sigma  </td><td>109.840793879</td><td>0.491074338963</td><td>6.52707126917</td><td>0.308773258025</td><td>1.00010761815</td><td>0.310656449351</td><td>19.9975726686</td><td>18.3476199673</td><td>1.09195337443</td></tr>\n",
       "<tr><td>zeros  </td><td>0            </td><td>227           </td><td>0            </td><td>3             </td><td>0            </td><td>0             </td><td>0            </td><td>167          </td><td>2            </td></tr>\n",
       "<tr><td>missing</td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0             </td><td>0            </td><td>0            </td><td>0            </td></tr>\n",
       "<tr><td>0      </td><td>1.0          </td><td>0.0           </td><td>65.0         </td><td>1.0           </td><td>2.0          </td><td>1.0           </td><td>1.4          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>1      </td><td>2.0          </td><td>0.0           </td><td>72.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>6.7          </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>2      </td><td>3.0          </td><td>0.0           </td><td>70.0         </td><td>1.0           </td><td>1.0          </td><td>2.0           </td><td>4.9          </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "<tr><td>3      </td><td>4.0          </td><td>0.0           </td><td>76.0         </td><td>2.0           </td><td>2.0          </td><td>1.0           </td><td>51.2         </td><td>20.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>4      </td><td>5.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>12.3         </td><td>55.9         </td><td>6.0          </td></tr>\n",
       "<tr><td>5      </td><td>6.0          </td><td>1.0           </td><td>71.0         </td><td>1.0           </td><td>3.0          </td><td>2.0           </td><td>3.3          </td><td>0.0          </td><td>8.0          </td></tr>\n",
       "<tr><td>6      </td><td>7.0          </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>31.9         </td><td>0.0          </td><td>7.0          </td></tr>\n",
       "<tr><td>7      </td><td>8.0          </td><td>0.0           </td><td>61.0         </td><td>2.0           </td><td>4.0          </td><td>2.0           </td><td>66.7         </td><td>27.2         </td><td>7.0          </td></tr>\n",
       "<tr><td>8      </td><td>9.0          </td><td>0.0           </td><td>69.0         </td><td>1.0           </td><td>1.0          </td><td>1.0           </td><td>3.9          </td><td>24.0         </td><td>7.0          </td></tr>\n",
       "<tr><td>9      </td><td>10.0         </td><td>0.0           </td><td>68.0         </td><td>2.0           </td><td>1.0          </td><td>2.0           </td><td>13.0         </td><td>0.0          </td><td>6.0          </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a description of the prostate data\n",
    "prostate.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly split the dataset into ~70/30, training/test sets\n",
    "r = prostate[0].runif()\n",
    "train = prostate[r < 0.70]\n",
    "test = prostate[r >= 0.70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the response columns to factors (for binary classification problems)\n",
    "train[\"CAPSULE\"] = train[\"CAPSULE\"].asfactor()\n",
    "test[\"CAPSULE\"] = test[\"CAPSULE\"].asfactor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm Model Build progress: |███████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Build a (classification) GLM\n",
    "from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "prostate_glm = H2OGeneralizedLinearEstimator(family=\"binomial\", alpha=[0.5])\n",
    "prostate_glm.train(x=[\"AGE\", \"RACE\", \"PSA\", \"VOL\", \"GLEASON\"],y=\"CAPSULE\", training_frame=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGeneralizedLinearEstimator :  Generalized Linear Modeling\n",
      "Model Key:  GLM_model_python_1473856953662_1\n",
      "GLM Model: summary\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>family</b></td>\n",
       "<td><b>link</b></td>\n",
       "<td><b>regularization</b></td>\n",
       "<td><b>number_of_predictors_total</b></td>\n",
       "<td><b>number_of_active_predictors</b></td>\n",
       "<td><b>number_of_iterations</b></td>\n",
       "<td><b>training_frame</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>binomial</td>\n",
       "<td>logit</td>\n",
       "<td>Elastic Net (alpha = 0.5, lambda = 4.435E-4 )</td>\n",
       "<td>5</td>\n",
       "<td>5</td>\n",
       "<td>4</td>\n",
       "<td>py_4_sid_9b7a</td></tr></table></div>"
      ],
      "text/plain": [
       "    family    link    regularization                                 number_of_predictors_total    number_of_active_predictors    number_of_iterations    training_frame\n",
       "--  --------  ------  ---------------------------------------------  ----------------------------  -----------------------------  ----------------------  ----------------\n",
       "    binomial  logit   Elastic Net (alpha = 0.5, lambda = 4.435E-4 )  5                             5                              4                       py_4_sid_9b7a"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.178271976724\n",
      "RMSE: 0.422222662494\n",
      "LogLoss: 0.527514252855\n",
      "Null degrees of freedom: 259\n",
      "Residual degrees of freedom: 254\n",
      "Null deviance: 354.862744265\n",
      "Residual deviance: 274.307411485\n",
      "AIC: 286.307411485\n",
      "AUC: 0.798778644416\n",
      "Gini: 0.597557288832\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.324184821812: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>96.0</td>\n",
       "<td>53.0</td>\n",
       "<td>0.3557</td>\n",
       "<td> (53.0/149.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>21.0</td>\n",
       "<td>90.0</td>\n",
       "<td>0.1892</td>\n",
       "<td> (21.0/111.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>117.0</td>\n",
       "<td>143.0</td>\n",
       "<td>0.2846</td>\n",
       "<td> (74.0/260.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      96   53   0.3557   (53.0/149.0)\n",
       "1      21   90   0.1892   (21.0/111.0)\n",
       "Total  117  143  0.2846   (74.0/260.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.3241848</td>\n",
       "<td>0.7086614</td>\n",
       "<td>142.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1793363</td>\n",
       "<td>0.8143075</td>\n",
       "<td>212.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5677960</td>\n",
       "<td>0.7108434</td>\n",
       "<td>75.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5062028</td>\n",
       "<td>0.7384615</td>\n",
       "<td>92.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9888923</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.1003694</td>\n",
       "<td>1.0</td>\n",
       "<td>242.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9888923</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.4822589</td>\n",
       "<td>0.4614783</td>\n",
       "<td>102.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.4319229</td>\n",
       "<td>0.7114094</td>\n",
       "<td>121.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.4516746</td>\n",
       "<td>0.7293972</td>\n",
       "<td>111.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.324185     0.708661  142\n",
       "max f2                       0.179336     0.814307  212\n",
       "max f0point5                 0.567796     0.710843  75\n",
       "max accuracy                 0.506203     0.738462  92\n",
       "max precision                0.988892     1         0\n",
       "max recall                   0.100369     1         242\n",
       "max specificity              0.988892     1         0\n",
       "max absolute_mcc             0.482259     0.461478  102\n",
       "max min_per_class_accuracy   0.431923     0.711409  121\n",
       "max mean_per_class_accuracy  0.451675     0.729397  111"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 42.69 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0115385</td>\n",
       "<td>0.9821549</td>\n",
       "<td>2.3423423</td>\n",
       "<td>2.3423423</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0270270</td>\n",
       "<td>134.2342342</td>\n",
       "<td>134.2342342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0230769</td>\n",
       "<td>0.9661381</td>\n",
       "<td>2.3423423</td>\n",
       "<td>2.3423423</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0540541</td>\n",
       "<td>134.2342342</td>\n",
       "<td>134.2342342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0307692</td>\n",
       "<td>0.9548820</td>\n",
       "<td>2.3423423</td>\n",
       "<td>2.3423423</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0180180</td>\n",
       "<td>0.0720721</td>\n",
       "<td>134.2342342</td>\n",
       "<td>134.2342342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0423077</td>\n",
       "<td>0.9422233</td>\n",
       "<td>2.3423423</td>\n",
       "<td>2.3423423</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0270270</td>\n",
       "<td>0.0990991</td>\n",
       "<td>134.2342342</td>\n",
       "<td>134.2342342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.9285748</td>\n",
       "<td>2.3423423</td>\n",
       "<td>2.3423423</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0180180</td>\n",
       "<td>0.1171171</td>\n",
       "<td>134.2342342</td>\n",
       "<td>134.2342342</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.8568971</td>\n",
       "<td>2.1621622</td>\n",
       "<td>2.2522523</td>\n",
       "<td>0.9230769</td>\n",
       "<td>0.9615385</td>\n",
       "<td>0.1081081</td>\n",
       "<td>0.2252252</td>\n",
       "<td>116.2162162</td>\n",
       "<td>125.2252252</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.7307997</td>\n",
       "<td>1.8018018</td>\n",
       "<td>2.1021021</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.8974359</td>\n",
       "<td>0.0900901</td>\n",
       "<td>0.3153153</td>\n",
       "<td>80.1801802</td>\n",
       "<td>110.2102102</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.6530328</td>\n",
       "<td>1.2612613</td>\n",
       "<td>1.8918919</td>\n",
       "<td>0.5384615</td>\n",
       "<td>0.8076923</td>\n",
       "<td>0.0630631</td>\n",
       "<td>0.3783784</td>\n",
       "<td>26.1261261</td>\n",
       "<td>89.1891892</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.5646024</td>\n",
       "<td>1.6216216</td>\n",
       "<td>1.8018018</td>\n",
       "<td>0.6923077</td>\n",
       "<td>0.7692308</td>\n",
       "<td>0.1621622</td>\n",
       "<td>0.5405405</td>\n",
       "<td>62.1621622</td>\n",
       "<td>80.1801802</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4808273</td>\n",
       "<td>1.1711712</td>\n",
       "<td>1.6441441</td>\n",
       "<td>0.5</td>\n",
       "<td>0.7019231</td>\n",
       "<td>0.1171171</td>\n",
       "<td>0.6576577</td>\n",
       "<td>17.1171171</td>\n",
       "<td>64.4144144</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3693529</td>\n",
       "<td>0.9009009</td>\n",
       "<td>1.4954955</td>\n",
       "<td>0.3846154</td>\n",
       "<td>0.6384615</td>\n",
       "<td>0.0900901</td>\n",
       "<td>0.7477477</td>\n",
       "<td>-9.9099099</td>\n",
       "<td>49.5495495</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.2816730</td>\n",
       "<td>0.9009009</td>\n",
       "<td>1.3963964</td>\n",
       "<td>0.3846154</td>\n",
       "<td>0.5961538</td>\n",
       "<td>0.0900901</td>\n",
       "<td>0.8378378</td>\n",
       "<td>-9.9099099</td>\n",
       "<td>39.6396396</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.2481746</td>\n",
       "<td>0.3603604</td>\n",
       "<td>1.2483912</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.5329670</td>\n",
       "<td>0.0360360</td>\n",
       "<td>0.8738739</td>\n",
       "<td>-63.9639640</td>\n",
       "<td>24.8391248</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1996907</td>\n",
       "<td>0.7207207</td>\n",
       "<td>1.1824324</td>\n",
       "<td>0.3076923</td>\n",
       "<td>0.5048077</td>\n",
       "<td>0.0720721</td>\n",
       "<td>0.9459459</td>\n",
       "<td>-27.9279279</td>\n",
       "<td>18.2432432</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.1092359</td>\n",
       "<td>0.3603604</td>\n",
       "<td>1.0910911</td>\n",
       "<td>0.1538462</td>\n",
       "<td>0.4658120</td>\n",
       "<td>0.0360360</td>\n",
       "<td>0.9819820</td>\n",
       "<td>-63.9639640</td>\n",
       "<td>9.1091091</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0007944</td>\n",
       "<td>0.1801802</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0769231</td>\n",
       "<td>0.4269231</td>\n",
       "<td>0.0180180</td>\n",
       "<td>1.0</td>\n",
       "<td>-81.9819820</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0115385                   0.982155           2.34234   2.34234            1                1                           0.027027        0.027027                   134.234   134.234\n",
       "    2        0.0230769                   0.966138           2.34234   2.34234            1                1                           0.027027        0.0540541                  134.234   134.234\n",
       "    3        0.0307692                   0.954882           2.34234   2.34234            1                1                           0.018018        0.0720721                  134.234   134.234\n",
       "    4        0.0423077                   0.942223           2.34234   2.34234            1                1                           0.027027        0.0990991                  134.234   134.234\n",
       "    5        0.05                        0.928575           2.34234   2.34234            1                1                           0.018018        0.117117                   134.234   134.234\n",
       "    6        0.1                         0.856897           2.16216   2.25225            0.923077         0.961538                    0.108108        0.225225                   116.216   125.225\n",
       "    7        0.15                        0.7308             1.8018    2.1021             0.769231         0.897436                    0.0900901       0.315315                   80.1802   110.21\n",
       "    8        0.2                         0.653033           1.26126   1.89189            0.538462         0.807692                    0.0630631       0.378378                   26.1261   89.1892\n",
       "    9        0.3                         0.564602           1.62162   1.8018             0.692308         0.769231                    0.162162        0.540541                   62.1622   80.1802\n",
       "    10       0.4                         0.480827           1.17117   1.64414            0.5              0.701923                    0.117117        0.657658                   17.1171   64.4144\n",
       "    11       0.5                         0.369353           0.900901  1.4955             0.384615         0.638462                    0.0900901       0.747748                   -9.90991  49.5495\n",
       "    12       0.6                         0.281673           0.900901  1.3964             0.384615         0.596154                    0.0900901       0.837838                   -9.90991  39.6396\n",
       "    13       0.7                         0.248175           0.36036   1.24839            0.153846         0.532967                    0.036036        0.873874                   -63.964   24.8391\n",
       "    14       0.8                         0.199691           0.720721  1.18243            0.307692         0.504808                    0.0720721       0.945946                   -27.9279  18.2432\n",
       "    15       0.9                         0.109236           0.36036   1.09109            0.153846         0.465812                    0.036036        0.981982                   -63.964   9.10911\n",
       "    16       1                           0.000794445        0.18018   1                  0.0769231        0.426923                    0.018018        1                          -81.982   0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>iteration</b></td>\n",
       "<td><b>negative_log_likelihood</b></td>\n",
       "<td><b>objective</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:45:09</td>\n",
       "<td> 0.000 sec</td>\n",
       "<td>0</td>\n",
       "<td>177.4313721</td>\n",
       "<td>0.6824284</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:45:09</td>\n",
       "<td> 0.172 sec</td>\n",
       "<td>1</td>\n",
       "<td>140.7453383</td>\n",
       "<td>0.5417682</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:45:09</td>\n",
       "<td> 0.206 sec</td>\n",
       "<td>2</td>\n",
       "<td>137.3005519</td>\n",
       "<td>0.5287510</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:45:09</td>\n",
       "<td> 0.249 sec</td>\n",
       "<td>3</td>\n",
       "<td>137.1549538</td>\n",
       "<td>0.5282564</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2016-09-14 14:45:09</td>\n",
       "<td> 0.332 sec</td>\n",
       "<td>4</td>\n",
       "<td>137.1537057</td>\n",
       "<td>0.5282552</td></tr></table></div>"
      ],
      "text/plain": [
       "    timestamp            duration    iteration    negative_log_likelihood    objective\n",
       "--  -------------------  ----------  -----------  -------------------------  -----------\n",
       "    2016-09-14 14:45:09  0.000 sec   0            177.431                    0.682428\n",
       "    2016-09-14 14:45:09  0.172 sec   1            140.745                    0.541768\n",
       "    2016-09-14 14:45:09  0.206 sec   2            137.301                    0.528751\n",
       "    2016-09-14 14:45:09  0.249 sec   3            137.155                    0.528256\n",
       "    2016-09-14 14:45:09  0.332 sec   4            137.154                    0.528255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the model\n",
    "prostate_glm.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glm prediction progress: |████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th style=\"text-align: right;\">  predict</th><th style=\"text-align: right;\">       p0</th><th style=\"text-align: right;\">       p1</th></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.73903  </td><td style=\"text-align: right;\">0.26097  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.199239 </td><td style=\"text-align: right;\">0.800761 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.574052 </td><td style=\"text-align: right;\">0.425948 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.638726 </td><td style=\"text-align: right;\">0.361274 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.944994 </td><td style=\"text-align: right;\">0.0550062</td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.445304 </td><td style=\"text-align: right;\">0.554696 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.0714216</td><td style=\"text-align: right;\">0.928578 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.592452 </td><td style=\"text-align: right;\">0.407548 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        1</td><td style=\"text-align: right;\">0.574141 </td><td style=\"text-align: right;\">0.425859 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">        0</td><td style=\"text-align: right;\">0.905267 </td><td style=\"text-align: right;\">0.0947333</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict on the test set and show the first ten predictions\n",
    "predictions = prostate_glm.predict(test)\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomialGLM: glm\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.176422197124\n",
      "RMSE: 0.420026424316\n",
      "LogLoss: 0.521715140997\n",
      "Null degrees of freedom: 119\n",
      "Residual degrees of freedom: 114\n",
      "Null deviance: 158.347430806\n",
      "Residual deviance: 125.211633839\n",
      "AIC: 137.211633839\n",
      "AUC: 0.788461538462\n",
      "Gini: 0.576923076923\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.293832331011: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>51.0</td>\n",
       "<td>27.0</td>\n",
       "<td>0.3462</td>\n",
       "<td> (27.0/78.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>7.0</td>\n",
       "<td>35.0</td>\n",
       "<td>0.1667</td>\n",
       "<td> (7.0/42.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>58.0</td>\n",
       "<td>62.0</td>\n",
       "<td>0.2833</td>\n",
       "<td> (34.0/120.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0    1    Error    Rate\n",
       "-----  ---  ---  -------  ------------\n",
       "0      51   27   0.3462   (27.0/78.0)\n",
       "1      7    35   0.1667   (7.0/42.0)\n",
       "Total  58   62   0.2833   (34.0/120.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2938323</td>\n",
       "<td>0.6730769</td>\n",
       "<td>60.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.2140532</td>\n",
       "<td>0.7894737</td>\n",
       "<td>77.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.5483174</td>\n",
       "<td>0.6645570</td>\n",
       "<td>27.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.5483174</td>\n",
       "<td>0.7583333</td>\n",
       "<td>27.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9980830</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0981916</td>\n",
       "<td>1.0</td>\n",
       "<td>104.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9980830</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2938323</td>\n",
       "<td>0.4649980</td>\n",
       "<td>60.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.3836897</td>\n",
       "<td>0.7051282</td>\n",
       "<td>51.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.2938323</td>\n",
       "<td>0.7435897</td>\n",
       "<td>60.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.293832     0.673077  60\n",
       "max f2                       0.214053     0.789474  77\n",
       "max f0point5                 0.548317     0.664557  27\n",
       "max accuracy                 0.548317     0.758333  27\n",
       "max precision                0.998083     1         0\n",
       "max recall                   0.0981916    1         104\n",
       "max specificity              0.998083     1         0\n",
       "max absolute_mcc             0.293832     0.464998  60\n",
       "max min_per_class_accuracy   0.38369      0.705128  51\n",
       "max mean_per_class_accuracy  0.293832     0.74359   60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 35.00 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0166667</td>\n",
       "<td>0.9711541</td>\n",
       "<td>2.8571429</td>\n",
       "<td>2.8571429</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.0476190</td>\n",
       "<td>185.7142857</td>\n",
       "<td>185.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.025</td>\n",
       "<td>0.9233955</td>\n",
       "<td>2.8571429</td>\n",
       "<td>2.8571429</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.0714286</td>\n",
       "<td>185.7142857</td>\n",
       "<td>185.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0333333</td>\n",
       "<td>0.9091811</td>\n",
       "<td>2.8571429</td>\n",
       "<td>2.8571429</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.0952381</td>\n",
       "<td>185.7142857</td>\n",
       "<td>185.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0416667</td>\n",
       "<td>0.8992416</td>\n",
       "<td>2.8571429</td>\n",
       "<td>2.8571429</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.1190476</td>\n",
       "<td>185.7142857</td>\n",
       "<td>185.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.8055963</td>\n",
       "<td>2.8571429</td>\n",
       "<td>2.8571429</td>\n",
       "<td>1.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.1428571</td>\n",
       "<td>185.7142857</td>\n",
       "<td>185.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.7173722</td>\n",
       "<td>1.4285714</td>\n",
       "<td>2.1428571</td>\n",
       "<td>0.5</td>\n",
       "<td>0.75</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.2142857</td>\n",
       "<td>42.8571429</td>\n",
       "<td>114.2857143</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.6143368</td>\n",
       "<td>0.9523810</td>\n",
       "<td>1.7460317</td>\n",
       "<td>0.3333333</td>\n",
       "<td>0.6111111</td>\n",
       "<td>0.0476190</td>\n",
       "<td>0.2619048</td>\n",
       "<td>-4.7619048</td>\n",
       "<td>74.6031746</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.5608499</td>\n",
       "<td>2.8571429</td>\n",
       "<td>2.0238095</td>\n",
       "<td>1.0</td>\n",
       "<td>0.7083333</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.4047619</td>\n",
       "<td>185.7142857</td>\n",
       "<td>102.3809524</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.4921527</td>\n",
       "<td>1.6666667</td>\n",
       "<td>1.9047619</td>\n",
       "<td>0.5833333</td>\n",
       "<td>0.6666667</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.5714286</td>\n",
       "<td>66.6666667</td>\n",
       "<td>90.4761905</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.4148725</td>\n",
       "<td>0.7142857</td>\n",
       "<td>1.6071429</td>\n",
       "<td>0.25</td>\n",
       "<td>0.5625</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.6428571</td>\n",
       "<td>-28.5714286</td>\n",
       "<td>60.7142857</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.3046478</td>\n",
       "<td>1.4285714</td>\n",
       "<td>1.5714286</td>\n",
       "<td>0.5</td>\n",
       "<td>0.55</td>\n",
       "<td>0.1428571</td>\n",
       "<td>0.7857143</td>\n",
       "<td>42.8571429</td>\n",
       "<td>57.1428571</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.2430575</td>\n",
       "<td>0.7142857</td>\n",
       "<td>1.4285714</td>\n",
       "<td>0.25</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.8571429</td>\n",
       "<td>-28.5714286</td>\n",
       "<td>42.8571429</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.2001067</td>\n",
       "<td>0.7142857</td>\n",
       "<td>1.3265306</td>\n",
       "<td>0.25</td>\n",
       "<td>0.4642857</td>\n",
       "<td>0.0714286</td>\n",
       "<td>0.9285714</td>\n",
       "<td>-28.5714286</td>\n",
       "<td>32.6530612</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.1457033</td>\n",
       "<td>0.2380952</td>\n",
       "<td>1.1904762</td>\n",
       "<td>0.0833333</td>\n",
       "<td>0.4166667</td>\n",
       "<td>0.0238095</td>\n",
       "<td>0.9523810</td>\n",
       "<td>-76.1904762</td>\n",
       "<td>19.0476190</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0915625</td>\n",
       "<td>0.4761905</td>\n",
       "<td>1.1111111</td>\n",
       "<td>0.1666667</td>\n",
       "<td>0.3888889</td>\n",
       "<td>0.0476190</td>\n",
       "<td>1.0</td>\n",
       "<td>-52.3809524</td>\n",
       "<td>11.1111111</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0301206</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td>\n",
       "<td>0.35</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>-100.0</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    cumulative_response_rate    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  --------------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0166667                   0.971154           2.85714   2.85714            1                1                           0.047619        0.047619                   185.714   185.714\n",
       "    2        0.025                       0.923395           2.85714   2.85714            1                1                           0.0238095       0.0714286                  185.714   185.714\n",
       "    3        0.0333333                   0.909181           2.85714   2.85714            1                1                           0.0238095       0.0952381                  185.714   185.714\n",
       "    4        0.0416667                   0.899242           2.85714   2.85714            1                1                           0.0238095       0.119048                   185.714   185.714\n",
       "    5        0.05                        0.805596           2.85714   2.85714            1                1                           0.0238095       0.142857                   185.714   185.714\n",
       "    6        0.1                         0.717372           1.42857   2.14286            0.5              0.75                        0.0714286       0.214286                   42.8571   114.286\n",
       "    7        0.15                        0.614337           0.952381  1.74603            0.333333         0.611111                    0.047619        0.261905                   -4.7619   74.6032\n",
       "    8        0.2                         0.56085            2.85714   2.02381            1                0.708333                    0.142857        0.404762                   185.714   102.381\n",
       "    9        0.3                         0.492153           1.66667   1.90476            0.583333         0.666667                    0.166667        0.571429                   66.6667   90.4762\n",
       "    10       0.4                         0.414873           0.714286  1.60714            0.25             0.5625                      0.0714286       0.642857                   -28.5714  60.7143\n",
       "    11       0.5                         0.304648           1.42857   1.57143            0.5              0.55                        0.142857        0.785714                   42.8571   57.1429\n",
       "    12       0.6                         0.243057           0.714286  1.42857            0.25             0.5                         0.0714286       0.857143                   -28.5714  42.8571\n",
       "    13       0.7                         0.200107           0.714286  1.32653            0.25             0.464286                    0.0714286       0.928571                   -28.5714  32.6531\n",
       "    14       0.8                         0.145703           0.238095  1.19048            0.0833333        0.416667                    0.0238095       0.952381                   -76.1905  19.0476\n",
       "    15       0.9                         0.0915625          0.47619   1.11111            0.166667         0.388889                    0.047619        1                          -52.381   11.1111\n",
       "    16       1                           0.0301206          0         1                  0                0.35                        0               1                          -100      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Show default performance metrics\n",
    "performance = prostate_glm.model_performance(test)\n",
    "performance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1\n",
    "------------\n",
    "Please convert your demo for the iris data set. First we need to merge the input and the target into a data frame. In this assignment, we would like to predict the length of petal by using the length of sepal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris_df=pd.DataFrame(X[:, [0,2]],columns=[iris.feature_names[0],iris.feature_names[2]])\n",
    "iris_h2o=h2o.H2OFrame(iris_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>C1            </th><th>C2           </th></tr>\n",
       "<tr><td>type   </td><td>real          </td><td>real         </td></tr>\n",
       "<tr><td>mins   </td><td>4.3           </td><td>1.0          </td></tr>\n",
       "<tr><td>mean   </td><td>5.84333333333 </td><td>3.75866666667</td></tr>\n",
       "<tr><td>maxs   </td><td>7.9           </td><td>6.9          </td></tr>\n",
       "<tr><td>sigma  </td><td>0.828066127978</td><td>1.76442041995</td></tr>\n",
       "<tr><td>zeros  </td><td>0             </td><td>0            </td></tr>\n",
       "<tr><td>missing</td><td>0             </td><td>0            </td></tr>\n",
       "<tr><td>0      </td><td>5.1           </td><td>1.4          </td></tr>\n",
       "<tr><td>1      </td><td>4.9           </td><td>1.4          </td></tr>\n",
       "<tr><td>2      </td><td>4.7           </td><td>1.3          </td></tr>\n",
       "<tr><td>3      </td><td>4.6           </td><td>1.5          </td></tr>\n",
       "<tr><td>4      </td><td>5.0           </td><td>1.4          </td></tr>\n",
       "<tr><td>5      </td><td>5.4           </td><td>1.7          </td></tr>\n",
       "<tr><td>6      </td><td>4.6           </td><td>1.4          </td></tr>\n",
       "<tr><td>7      </td><td>5.0           </td><td>1.5          </td></tr>\n",
       "<tr><td>8      </td><td>4.4           </td><td>1.4          </td></tr>\n",
       "<tr><td>9      </td><td>4.9           </td><td>1.5          </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_h2o.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the colname of h2o data frame is lost, to get a better understand of your data frame you can reset the colnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>       </th><th>sepal length (cm)  </th><th>petal length (cm)  </th></tr>\n",
       "<tr><td>type   </td><td>real               </td><td>real               </td></tr>\n",
       "<tr><td>mins   </td><td>4.3                </td><td>1.0                </td></tr>\n",
       "<tr><td>mean   </td><td>5.84333333333      </td><td>3.75866666667      </td></tr>\n",
       "<tr><td>maxs   </td><td>7.9                </td><td>6.9                </td></tr>\n",
       "<tr><td>sigma  </td><td>0.828066127978     </td><td>1.76442041995      </td></tr>\n",
       "<tr><td>zeros  </td><td>0                  </td><td>0                  </td></tr>\n",
       "<tr><td>missing</td><td>0                  </td><td>0                  </td></tr>\n",
       "<tr><td>0      </td><td>5.1                </td><td>1.4                </td></tr>\n",
       "<tr><td>1      </td><td>4.9                </td><td>1.4                </td></tr>\n",
       "<tr><td>2      </td><td>4.7                </td><td>1.3                </td></tr>\n",
       "<tr><td>3      </td><td>4.6                </td><td>1.5                </td></tr>\n",
       "<tr><td>4      </td><td>5.0                </td><td>1.4                </td></tr>\n",
       "<tr><td>5      </td><td>5.4                </td><td>1.7                </td></tr>\n",
       "<tr><td>6      </td><td>4.6                </td><td>1.4                </td></tr>\n",
       "<tr><td>7      </td><td>5.0                </td><td>1.5                </td></tr>\n",
       "<tr><td>8      </td><td>4.4                </td><td>1.4                </td></tr>\n",
       "<tr><td>9      </td><td>4.9                </td><td>1.5                </td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris_h2o.set_names([iris.feature_names[0],iris.feature_names[2]])\n",
    "iris_h2o.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that our problem is a regression problem. \n",
    "Using help() to give a more details of the H2OGeneralizedLinearEstimator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(H2OGeneralizedLinearEstimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
